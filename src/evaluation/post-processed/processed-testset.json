[
  {
    "question": "What happens if a player lands on a property they do not wish to buy?",
    "ground_truths": "If a player does not wish to buy the property, the Banker sells it at auction to the highest bidder.",
    "reference": "You receive the Title Deed card showing ownership; place it faceup in front of you.If you do not wish to buy the property, the Banker sells it  at auction to the highest bidder. The buyer pays the Bank the amount of the bid in cash and receives the Title Deed card for that property. Any player, including the one who declined the option to buy it at the printed price, may bid. Bidding may start at any price.PAMNG When you land on property owned by another player, the owner collects rent from you in accordance  with the list printed  on its Title Deed card.If the property is mortgaged, no rent can be collected.",
    "metadata": "simple",
    "retrieved_contexts": [
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      ".(I) throwing doubles on any of your next three turns;  if you succeed in doing this you immediately  move forward the number of spaces shown by  your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3)  purchasing  the \"Get Out of Jail Free\" card from another player and playing it; (4)  paying a fine of $50 before  you roll the dice on either of your next two turns.If  you do not throw doubles by  your third turn, you must pay the $50 fine. Y o u  then get out of Jail and immediately move forward the number of spaces shown by  your throw.Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\" F R E E  P A R K I N G \" :  A player landing on this place does not receive any money, property or reward of any kind. This is just a \"free\" resting place.HOUSES: When you own all the propert~es in a color-group you may buy houses from the B a n k  and erect them on those properties.If  you buy one house, you may put it on any one of those properties.",
      "If there are a limited number of houses and hotels available and two or more players wish to buy more than the B a n k  h a s ,   the houses or hotels must be  sold at auction to the highest bidder.SELLING PROPERN: Unimproved  properties, railroads and util~ties (but not buildings) may be sold to any player a s  a private transaction for any amount the owner can get;  however, no property can be sold to another player if buildings are standing on any properties of that colorgroup.",
      "You receive the Title Deed card showing ownership; place it faceup in front of you.If you do not wish to buy the property, the Banker sells it  at auction to the highest bidder. The buyer pays the Bank the amount of the bid in cash and receives the Title Deed card for that property. Any player, including the one who declined the option to buy it at the printed price, may bid. Bidding may start at any price.PAMNG When you land on property owned by another player, the owner collects rent from you in accordance  with the list printed  on its Title Deed card.If the property is mortgaged, no rent can be collected."
    ],
    "response": "If a player lands on a property they do not wish to buy, they have the option to sell that property to another player at any time for a mutually agreeable price. This allows the player to avoid purchasing the property while still enabling the potential for a transaction with another player.\n\nThis information is derived from the context regarding property transactions in the game."
  },
  {
    "question": "What was Lizzie's creation that she sought to patent on 23 March 1903?",
    "ground_truths": "Lizzie sought to patent the Landlord's Game.",
    "reference": "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies. However, and of course unbeknownst to Lizzie at the time, it was the monopolist rules that would later capture the public's imagination.After years of tinkering, writing and pondering her new creation, Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
    "metadata": "simple",
    "retrieved_contexts": [
      "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies. However, and of course unbeknownst to Lizzie at the time, it was the monopolist rules that would later capture the public's imagination.After years of tinkering, writing and pondering her new creation, Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
      "She was angry, hurt and in search of revenge against a company that she felt had stolen her nowbest-selling idea. Parker Brothers might have the rights to her 1924-patented Landlord's Game, but they didn't tell the story of her game invention dating back to 1904 or that the game had been in the public domain for decades. She had invented the game, and she could prove it.The Evening Star reporter wrote that Lizzie's game 'did not get the popular hold it has today. It took Charles B Darrow, a Philadelphia engineer, who retrieved the game from the oblivion of the Patent Office and dressed it up a bit, to get it going.",
      "And so did Lizzie Magie. She died in 1948, a jobs was at the US Office of Education, where her colleagues knew her only as an elderly typist who talked about inventing games.As Charles Darrow reaped the rewards of the game's success, Lizzie Magie's role in the invention of Monopoly remained obscure. But in 1973, Ralph Anspach, a leftwing academic who was under legal attack from Parker Brothers over his creation of an Anti-Monopoly game, learned her story as he researched his case, seeking to undermine the company's hold on the intellectual property.",
      "In one corner were the Poor House and the Public Park, and across the board was the Jail. Another corner contained an image of the globe and an homage to Lizzie's political hero, the economist Henry George, whose ideas about putting the burden of taxation on wealthy landowners inspired the game: 'Labor upon Mother Earth Produces Wages.' Also included on the board were three words that have endured for more than a century after Lizzie scrawled them there: GO TO JAIL.Lizzie drew nine rectangular spaces along the edges of the board between each set of corners. In the centre of each nine-space grouping was a railroad, with spaces for rent or sale on either side."
    ],
    "response": "Lizzie sought to patent her creation known as the Landlord's Game on 23 March 1903. This game would later become significant in the history of board games, although it was not initially popular until it was revived by Charles B. Darrow in the mid-1930s. Despite her invention, Lizzie faced challenges regarding the recognition and rights to her game, particularly when it was commercialized by Parker Brothers."
  },
  {
    "question": "What is the main contribution of the study mentioned in the context?",
    "ground_truths": "The study introduced an adaptive retrieval-augmented generation framework using a multi-armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity.",
    "reference": "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks.",
    "metadata": "simple",
    "retrieved_contexts": [
      "When access to information is made equal, greater numbers of people can understand global events and their impact on people and communities. Together, we can demand better from the powerful and fight for democracy.Whether you give a little or a lot, your funding will power our reporting for the years to come. Support the Guardian from as little as \u20ac1 - it only takes a minute. If you can, please consider giving a regular amount each month or year. Thank you. `Summary of some image`",
      "3.3 Metrics. Following the approach of Jeong et al. (2024), in addition to reporting performance metrics of the generated results such as Exact Match (EM), F 1 , and Accuracy (Acc), we also report efficiency metrics of the retrieval strategy, Step. EM measures whether the predicted result exactly matches the ground truth, F 1 measures the overlap of words between the predicted answer and the ground truth, and Acc indicates whether the predicted answer contains the ground truth. Step denotes the number of retrieval steps required by the selected retrieval strategy.",
      "However, this approach may hinder the versatility of language models or introduce unnecessary or off-topic* Equally contributed authors\u2020 Corresponding authorpassages. To address this issue, methods such as SEAKR (Yao et al., 2024) and FLARE (Jiang et al., 2023) have been designed to perform active retrieval only when necessary.Furthermore, AdaptiveRAG (Jeong et al., 2024) argues that real-world queries often vary in difficulty, such as the number of reasoning steps required or the depth of information needed to answer a query. Thus, applying a single retrieval method across all queries can be ineffective.",
      "Absolute Necessity rectangles offered goods like bread and shelter, and Franchise spaces offered services such as water and light. As gamers made their way around the board, they performed labour and earned wages. Every time players passed the Mother Earth space, they were 'supposed to have performed so much labor upon Mother Earth' that they received $100 in wages. Players who ran out of money were sent to the Poor House.Players who trespassed on land were sent to Jail, and there the unfortunate individuals had to linger until serving out their time or paying a $50 fine."
    ],
    "response": "The main contribution of the study is the development of a method that achieves a balance between performance and efficiency in retrieval strategies. The study reports performance metrics such as Exact Match (EM), F1, and Accuracy (Acc), while also considering the efficiency metric of the number of retrieval steps (Step). The experimental results indicate that the proposed method surpasses baseline performance metrics and requires relatively fewer retrieval steps, demonstrating improvements across all single-step datasets. This highlights the effectiveness of the method in enhancing both the accuracy of results and the efficiency of the retrieval process."
  },
  {
    "question": "What is the purpose of the dynamic, fine-grained reward function in the bandit framework?",
    "ground_truths": "The dynamic, fine-grained reward function is designed to penalize inefficient generation strategies, even if they lead to correct results, ensuring that the model prioritizes both accuracy and computational efficiency.",
    "reference": "The bandit framework requires only partial information for supervision; specifically, the model is supervised by the feedback of the chosen generation strategy, without indiscriminately penalizing the strategies that were not selected. This introduces greater flexibility by allowing the model to explore different generation strategies and obtain a more comprehensive selection.Second, to tackle the issue of inaccurate heuristic supervision of retrieval costs and the varying costs associated with different generation strategies, we design a dynamic, fine-grained reward function. This function penalizes inefficient generation strategies, even if they lead to correct results, ensuring that the model not only prioritizes accuracy but also optimizes computational efficiency.We evaluated our framework on both single-hop and multi-hop datasets. Results demonstrate that our method achieves SOTA generation accuracy while reducing retrieval costs by 20%.",
    "metadata": "simple",
    "retrieved_contexts": [
      "The bandit framework requires only partial information for supervision; specifically, the model is supervised by the feedback of the chosen generation strategy, without indiscriminately penalizing the strategies that were not selected. This introduces greater flexibility by allowing the model to explore different generation strategies and obtain a more comprehensive selection.Second, to tackle the issue of inaccurate heuristic supervision of retrieval costs and the varying costs associated with different generation strategies, we design a dynamic, fine-grained reward function. This function penalizes inefficient generation strategies, even if they lead to correct results, ensuring that the model not only prioritizes accuracy but also optimizes computational efficiency.We evaluated our framework on both single-hop and multi-hop datasets. Results demonstrate that our method achieves SOTA generation accuracy while reducing retrieval costs by 20%.",
      "1987. The multi-armed bandit problem: decomposition and computation. Mathematics of Operations Research , 12(2):262-268.Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.",
      "Limitations. Our reinforcement learning-based approach for adaptive retrieval in language models demonstrates promising results; however, it is not without limitations. The framework's dependence on the specific structure of the multi-armed bandit algorithm can introduce challenges in scalability and adaptability to new, unseen query types. Future work could explore more efficient algorithms that maintain performance while reducing computational demands.",
      "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn"
    ],
    "response": "The purpose of the dynamic, fine-grained reward function in the bandit framework is twofold. First, it allows for greater flexibility in the model by enabling it to explore various generation strategies without penalizing those that were not selected. This is important because the bandit framework operates with partial information, relying on feedback from the chosen strategy.\n\nSecond, the dynamic, fine-grained reward function addresses the challenge of inaccurate heuristic supervision related to retrieval costs and the differing costs of various generation strategies. It specifically penalizes inefficient generation strategies, even if they yield correct results. This ensures that the model not only focuses on achieving accuracy but also optimizes computational efficiency.\n\nIn summary, this reward function enhances the model's ability to balance accuracy and efficiency in its decision-making process."
  },
  {
    "question": "What happens if your token lands on the 'Go to Jail' space in the game?",
    "ground_truths": "When your token lands on the space marked 'Go to Jail', you must move it directly into Jail and cannot collect your $200 salary in that move. Your turn ends when you are sent to Jail.",
    "reference": ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
    "metadata": "simple",
    "retrieved_contexts": [
      ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
      "After you have completed your play, the turn passes to the left. The tokens remain on the spaces qccupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time.According to the space your token reaches, you may be entitled  to buy real estate or other properties  or obliged  to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc.If you throw doubles, you move your token a s   usual, the sum of the two dice, and are subject to any privileges  or penalties pertaining  to the space on which you land. Retaining the dice, throw again and move your token a s   before.",
      "If  you throw doubles three times in succession, move your token immediately to the space marked \"In Jail\" (see JAIL).. .\"GO\": Each time a player's token lands on or passes over GO, whether by throwing the dice or drawing a card, the Banker pays himther a $200  sala,ry.The $200 is paid only once each time kound the board. However, if a player passing GO on the throw of the dice lands 2 spaces beyond it on Community Chest, or 7 spaces beyond it on Chance, and draws the \"Advance to GO\" card, helshe  collects $200 for passing GO the first time and another $200 for reaching it the second time by instructions on the card. `Summary of some image`   BUYING PROPERTY: Whenever you land on an unowned property you may buy that property from the Bank at its printed price.",
      ".(I) throwing doubles on any of your next three turns;  if you succeed in doing this you immediately  move forward the number of spaces shown by  your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3)  purchasing  the \"Get Out of Jail Free\" card from another player and playing it; (4)  paying a fine of $50 before  you roll the dice on either of your next two turns.If  you do not throw doubles by  your third turn, you must pay the $50 fine. Y o u  then get out of Jail and immediately move forward the number of spaces shown by  your throw.Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\" F R E E  P A R K I N G \" :  A player landing on this place does not receive any money, property or reward of any kind. This is just a \"free\" resting place.HOUSES: When you own all the propert~es in a color-group you may buy houses from the B a n k  and erect them on those properties.If  you buy one house, you may put it on any one of those properties."
    ],
    "response": "If your token lands on the \"Go to Jail\" space in the game, you are sent directly to Jail. This means you cannot collect your $200 salary for that turn, as your turn ends immediately when you are sent to Jail. \n\nHowever, if you land on the \"Go to Jail\" space through regular gameplay (not as a result of being sent there), you are considered \"Just Visiting,\" which incurs no penalty, and you will continue your turn as normal on your next turn.\n\nAdditionally, if you throw doubles three times in succession, you also move your token directly to Jail. \n\nThis information is derived from the rules regarding the \"Go to Jail\" space and the consequences of landing there."
  },
  {
    "question": "What strategy is used to balance exploration and exploitation in the generation selection process?",
    "ground_truths": "An epsilon-greedy strategy is used to balance the trade-off between exploration and exploitation.",
    "reference": "2.2 Query Encoding and Arm Selection. To overcome the limitations of attributing each query to a single generation method, we reformulate the generation selection as a trial-and-error reinforcement learning problem, where each generation method is treated as an action (i.e. an arm) in a multi-armed bandit framework.We employ DistilBERT, a lightweight pretrained language model (PLM), to encode user queries, generating an action distribution z = f \u03b8 ( x ) . Directly supervising this output could cause the system to overly favor a single generation method, leading to sub-optimal local convergence.To prevent this, we incorporate an epsilongreedy strategy (Langford and Zhang, 2007) to balance the trade-off between exploration and exploitation (Auer, 2002; Auer et al., 2002). This ensures that the system primarily utilizes the bestperforming generation methods while still exploring other options to improve long-term performance. Specifically, the 'arm' is chosen as a = arg max( z ) with probability 1 -\u03f5 , or a random generation method with probability \u03f5 .",
    "metadata": "simple",
    "retrieved_contexts": [
      "The bandit framework requires only partial information for supervision; specifically, the model is supervised by the feedback of the chosen generation strategy, without indiscriminately penalizing the strategies that were not selected. This introduces greater flexibility by allowing the model to explore different generation strategies and obtain a more comprehensive selection.Second, to tackle the issue of inaccurate heuristic supervision of retrieval costs and the varying costs associated with different generation strategies, we design a dynamic, fine-grained reward function. This function penalizes inefficient generation strategies, even if they lead to correct results, ensuring that the model not only prioritizes accuracy but also optimizes computational efficiency.We evaluated our framework on both single-hop and multi-hop datasets. Results demonstrate that our method achieves SOTA generation accuracy while reducing retrieval costs by 20%.",
      "2.2 Query Encoding and Arm Selection. To overcome the limitations of attributing each query to a single generation method, we reformulate the generation selection as a trial-and-error reinforcement learning problem, where each generation method is treated as an action (i.e. an arm) in a multi-armed bandit framework.We employ DistilBERT, a lightweight pretrained language model (PLM), to encode user queries, generating an action distribution z = f \u03b8 ( x ) . Directly supervising this output could cause the system to overly favor a single generation method, leading to sub-optimal local convergence.To prevent this, we incorporate an epsilongreedy strategy (Langford and Zhang, 2007) to balance the trade-off between exploration and exploitation (Auer, 2002; Auer et al., 2002). This ensures that the system primarily utilizes the bestperforming generation methods while still exploring other options to improve long-term performance. Specifically, the 'arm' is chosen as a = arg max( z ) with probability 1 -\u03f5 , or a random generation method with probability \u03f5 .",
      "This strict supervision ignores scenarios where more complex strategies might offer better context or more comprehensive answers. Second, this heuristic approach is ambiguous because retrieval costs vary according to the query's difficulty, what constitutes the least cost can differ significantly between queries of different complexities.To overcome these limitations, we propose a M ulti-arm B andit-based framework for A daptive R etrievalA ugmented G eneration (MBA-RAG) Fig. 1, that introduces both flexibility and costawareness into the generation process.First, to address the rigidity of single-label supervision, we employ a multi-armed bandit algo-   ***Figure 1: On the left, the AdaptiveRAG pipeline relies on an inaccurate heuristic approach to assign queries of different complexities to a single generation process. On the right, we propose an MBA-RAG framework that allows the model to explore the merits of different generation methods and rewards it based on fine-grained assessments of generation quality and cost.***   `Summary of some image`   rithm (Katehakis and Veinott Jr, 1987).",
      "2 Method. Using a single retrieval method for all queries may not always be effective. In this section, we introduce a RAG framework based on a multi-arm bandit approach that dynamically selects the optimal generation method to balance generation quality and computational efficiency."
    ],
    "response": "The strategy used to balance exploration and exploitation in the generation selection process is based on an epsilon-greedy approach within a multi-armed bandit framework. This method allows the system to primarily utilize the best-performing generation methods while still exploring other options to enhance long-term performance.\n\nIn this approach, the model selects the best-performing generation method (the \"arm\") with a high probability (1 - \u03f5), while also allowing for random selection of other generation methods with a lower probability (\u03f5). This balance ensures that the model does not become overly reliant on a single strategy, which could lead to sub-optimal performance, and instead encourages exploration of various strategies to improve overall effectiveness.\n\nThis information was derived from the context discussing the multi-armed bandit framework and the epsilon-greedy strategy used to manage the trade-off between exploration and exploitation."
  },
  {
    "question": "What are the two stages involved in the RAG process?",
    "ground_truths": "The RAG process includes a retrieval stage where the module R retrieves relevant documents D for a query x, and a generation stage where the LLM uses x and D to generate the response.",
    "reference": "2.1 Preliminaries. The RAG process (Lewis et al., 2020) includes a retrieval stage where the module R retrieves relevant documents D for a query x , and a generation stage where the LLM uses x and D to generate the response \u00af a = LLM ( y t | x, D ) .",
    "metadata": "simple",
    "retrieved_contexts": [
      "2.1 Preliminaries. The RAG process (Lewis et al., 2020) includes a retrieval stage where the module R retrieves relevant documents D for a query x , and a generation stage where the LLM uses x and D to generate the response \u00af a = LLM ( y t | x, D ) .",
      "On the NQ dataset, our results are roughly on par with Adaptive-RAG, but with an increase in steps. This is because Adaptive-RAG, when constructing the dataset, set the condition that when zero, one, or multiple retrieval paths could yield the correct answer, the path requiring the fewest steps would be chosen as the correct label, with others marked as incorrect. However, this does not reflect reality as other paths can also yield correct answers.",
      "2 Method. Using a single retrieval method for all queries may not always be effective. In this section, we introduce a RAG framework based on a multi-arm bandit approach that dynamically selects the optimal generation method to balance generation quality and computational efficiency.",
      "3.5 Main Results. We report the average results across six datasets as shown in Table 1, and the results for each individual dataset as shown in Table 2. Note that while we focus on performance metrics such as EM, F 1 , and Acc, we also consider efficiency metrics like Step. The experimental results demonstrate that our method achieves a balance between the two, surpassing the baseline in performance metrics while requiring relatively fewer steps.As shown in Table 2, our method has achieved performance improvements on all single-step datasets, with significant gains observed on the   ***Table 2: Results on each of a collection of datasets with FLAN-T5-XL (3B) as the LLM. Items marked with \u2217 have results from Jeong et al."
    ],
    "response": "The RAG process consists of two main stages:\n\n1. **Retrieval Stage**: In this stage, the module retrieves relevant documents based on a given query.\n2. **Generation Stage**: Here, a language model uses the query and the retrieved documents to generate a response.\n\nThis information was derived from the context that describes the RAG process as involving these two distinct stages."
  },
  {
    "question": "What features did The Landlord's Game include?",
    "ground_truths": "The Landlord's Game included play money, deeds and properties that could be bought and sold, borrowing money from the bank or each other, paying taxes, and a path that allowed players to circle the board.",
    "reference": "The Landlord's Game. Photograph: Tom Forsyth. Lizzie's game featured play money and deeds and properties that could be bought and sold. Players borrowed money, either from the bank or from each other, and they had to pay taxes. And it featured a path that allowed players to circle the board - in contrast to the linear-path design used by many games at the time.",
    "metadata": "simple",
    "retrieved_contexts": [
      "The Landlord's Game. Photograph: Tom Forsyth. Lizzie's game featured play money and deeds and properties that could be bought and sold. Players borrowed money, either from the bank or from each other, and they had to pay taxes. And it featured a path that allowed players to circle the board - in contrast to the linear-path design used by many games at the time.",
      "Serving out their time meant waiting until they threw a double. 'The rallying and chaffing of the others when one player finds himself an inmate of the jail, and the expressions of mock sympathy and condolence when one is obliged to betake himself to the poor house, make a large part of the fun and merriment of the game,' Lizzie said.From its inception, the Landlord's Game aimed to seize on the natural human instinct to compete. And, somewhat surprisingly, Lizzie created two sets of rules: an anti-monopolist set in which all were rewarded when wealth was created, and a monopolist set in which the goal was to create monopolies and crush opponents.",
      "When the game started to take off in the mid-1930s, the company bought up the rights to other related games to preserve its territory. For the patent to the Landlord's Game and two other game ideas, Lizzie reportedly received $500 - and no royalties.At first, Lizzie did not suspect the true motives for the purchase of her game. When a prototype of Parker Brothers' version of the Landlord's Game arrived at her home in Arlington, she was delighted. In a letter to Foster Parker, nephew of George and the company's treasurer, she wrote that there had been 'a song in my heart' ever since the game had arrived. 'Some day, I hope,' she went on, 'you will publish other games of mine, but I don't think any one of them will be as much trouble to you or as important to me as this one, and I'm sure I wouldn't make so much fuss over them.'Eventually, though, the truth dawned on her - and she became publicly angry. In January of 1936 she gave interviews to the Washington Post and the Washington Evening Star.",
      "It sells and auctions properties and hands out the~r proper  Title Deed cards; it sells houses and hotels to the players and loans money when required on mortgages. `Summary of some image`   The Bank collects all taxes, fines,  loans and interest, and the price of all properties  which it sells and  auctions.The Bank nwer \"goes broke.\" If the Bank runs out of money, the Banker may issue a s   much more a s   needed by  writing on any ordinary paper.THE PLAY: Starting with the Banker, each player in turn throws the dice. `Summary of some image`   The player with the highest total starts the play: Place your token on the corner marked \"GO,\" throw the dice and move your token in the direction of the arrow the number of spaces indicated by  the dice."
    ],
    "response": "The Landlord's Game included several notable features:\n\n1. **Two Sets of Rules**: The game was designed with both an anti-monopolist set of rules, where all players benefited from wealth creation, and a monopolist set of rules, where the objective was to create monopolies and defeat opponents.\n\n2. **Objective**: The main goal of the game was to become the wealthiest player by buying, renting, and selling properties.\n\n3. **Game Setup**: Players started with $1,500 divided into various denominations and used tokens to represent themselves on the board. The game included Chance and Community Chest cards.\n\n4. **Jail Mechanics**: Players could end up in jail and had several options to get out, including throwing doubles, using a \"Get Out of Jail Free\" card, or paying a fine.\n\n5. **Property Management**: Players could buy and sell properties, as well as build houses and hotels on properties they owned, particularly when they owned all properties in a color group.\n\n6. **Free Parking**: Landing on the \"Free Parking\" space did not yield any rewards; it served as a resting place.\n\nThese features highlight the competitive nature of the game and its focus on property management and financial strategy."
  },
  {
    "question": "What does the Guardian suggest about the impact of equal access to information?",
    "ground_truths": "When access to information is made equal, greater numbers of people can understand global events and their impact on people and communities. Together, we can demand better from the powerful and fight for democracy.",
    "reference": "When access to information is made equal, greater numbers of people can understand global events and their impact on people and communities. Together, we can demand better from the powerful and fight for democracy.Whether you give a little or a lot, your funding will power our reporting for the years to come. Support the Guardian from as little as \u20ac1 - it only takes a minute. If you can, please consider giving a regular amount each month or year. Thank you. `Summary of some image`",
    "metadata": "simple",
    "retrieved_contexts": [
      "When access to information is made equal, greater numbers of people can understand global events and their impact on people and communities. Together, we can demand better from the powerful and fight for democracy.Whether you give a little or a lot, your funding will power our reporting for the years to come. Support the Guardian from as little as \u20ac1 - it only takes a minute. If you can, please consider giving a regular amount each month or year. Thank you. `Summary of some image`",
      "A new year means new opportunities, and we're hoping this year gives rise to some much-needed stability and progress. Whatever happens, the Guardian will be there, providing clarity and fearless, independent reporting from around the world, 24/7.Times are tough, and we know not everyone is in a position to pay for news. But as we're reader-funded, we rely on the ongoing generosity of those who can afford it. This vital support means millions can continue to read reliable reporting on the events shaping our world. Will you invest in the Guardian this year?Unlike many others, we have no billionaire owner, meaning we can fearlessly chase the truth and report it with integrity. 2023 will be no different; we will work with trademark determination and passion to bring you journalism that's always free from commercial or political interference. No one edits our editor or diverts our attention from what's most important.With your support, we'll continue to keep Guardian journalism open and free for everyone to read.",
      "However, this approach may hinder the versatility of language models or introduce unnecessary or off-topic* Equally contributed authors\u2020 Corresponding authorpassages. To address this issue, methods such as SEAKR (Yao et al., 2024) and FLARE (Jiang et al., 2023) have been designed to perform active retrieval only when necessary.Furthermore, AdaptiveRAG (Jeong et al., 2024) argues that real-world queries often vary in difficulty, such as the number of reasoning steps required or the depth of information needed to answer a query. Thus, applying a single retrieval method across all queries can be ineffective.",
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs."
    ],
    "response": "The Guardian suggests that equal access to information allows a greater number of people to understand global events and their impacts on communities. This collective understanding empowers individuals to demand accountability from those in power and advocate for democracy. The emphasis is on how equal access can enhance awareness and engagement in societal issues."
  },
  {
    "question": "In a scenario where several players are interested in purchasing more houses or hotels than what the bank currently possesses, what is the procedure to resolve this situation according to the rules?",
    "ground_truths": "The houses or hotels must be sold at auction to the highest bidder.",
    "reference": "If there are a limited number of houses and hotels available and two or more players wish to buy more than the B a n k  h a s ,   the houses or hotels must be  sold at auction to the highest bidder.SELLING PROPERN: Unimproved  properties, railroads and util~ties (but not buildings) may be sold to any player a s  a private transaction for any amount the owner can get;  however, no property can be sold to another player if buildings are standing on any properties of that colorgroup.",
    "metadata": "complex",
    "retrieved_contexts": [
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      "You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your debt is to another player, you must tum over to that player all that you have of value and retire from the game. In making this settlement,  if you own houses or hotels, you must retum these to the Bank in exchange for money to the extent of one-half the amount paid for them;  this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay  .",
      "`Summary of some image`   The player who mortgages property  retains possession of it and no other player may secure it by lifting the mortgage from the Bank. However, the owner may sell this mortgaged property to another player at any agreed price. If you are the new owner, you may lift the mortgage at once if you wish by  paying off the mortgage plus 10% interest to the Bank. If the mortgage is not lifted at once, you must pay the Bank 10% interest  when you buy the property  and if you lift the mortgage later you must pay the Bank an additional 10% interest a s  well as   the amount of the mortgage. n-   `Summary of some image`   BANKRUPTCY..",
      "If there are a limited number of houses and hotels available and two or more players wish to buy more than the B a n k  h a s ,   the houses or hotels must be  sold at auction to the highest bidder.SELLING PROPERN: Unimproved  properties, railroads and util~ties (but not buildings) may be sold to any player a s  a private transaction for any amount the owner can get;  however, no property can be sold to another player if buildings are standing on any properties of that colorgroup."
    ],
    "response": "In a situation where multiple players want to purchase more houses or hotels than the bank currently has available, the procedure is as follows:\n\n1. **Building Shortages**: If the bank has no houses or hotels to sell, players who wish to build must wait. They cannot proceed with their purchases until other players return or sell their houses or hotels back to the bank.\n\n2. **Selling Back to the Bank**: Players can sell their houses or hotels back to the bank at any time for half the price they originally paid. This action can help increase the supply of buildings available for purchase.\n\n3. **Building Evenly**: If players have houses on properties, they must build or sell evenly across their properties in a color group. For example, if a player has houses on two properties, they cannot build a third house on one property unless they have built on the other property as well.\n\n4. **Hotel Purchases**: A player can buy a hotel only after they have four houses on each property of a complete color group. They must return the four houses to the bank and pay the hotel price as indicated on the Title Deed card.\n\nIn summary, if the bank runs out of houses or hotels, players must wait for others to sell back their buildings to the bank before they can proceed with their purchases. This ensures a fair distribution of available properties."
  },
  {
    "question": "Considering the significant size difference between the classifiers used, what could be a potential reason for the performance variation between Adaptive-RAG, which employs T5-large, and the method that utilizes DistilBERT, especially when dealing with complex datasets like HotpotQA?",
    "ground_truths": "The method discussed uses DistilBERT (66M), which is 10 times smaller than the T5-large (770M) used by Adaptive-RAG.",
    "reference": "This may be because, compared to Adaptive-RAG which uses T5-large (770M) as the classifier, our method uses DistilBERT (66M), which is 10 times smaller. Un- like the other two datasets, HotpotQA is a very challenging dataset with complex question types like actoid comparison questions that demand high general knowledge performance from the model.",
    "metadata": "complex",
    "retrieved_contexts": [
      "This may be because, compared to Adaptive-RAG which uses T5-large (770M) as the classifier, our method uses DistilBERT (66M), which is 10 times smaller. Un- like the other two datasets, HotpotQA is a very challenging dataset with complex question types like actoid comparison questions that demand high general knowledge performance from the model.",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results.",
      "3.4 Experiment Settings. We use DistilBERT (Sanh et al., 2020) as the query encoding model. This model allows for efficient query encoding and ensures that the retrieval method selection is based on a robust representation of the query. The retrieval settings, dataset configurations, and generation model setups all follow the approach used by Adaptive-RAG (Jeong et al., 2024). We utilize BM25 as the retrieval model and FLAN-T5-XL (Chung et al., 2022) as the generation model. For the MBA-RAG retrieval, we employ the epsilon-greedy algorithm (Sutton and Barto, 1998) as the action strategy. The learning rate for the encoding model is set as 5e-5. ***Table 1: Averaged results on a collection of benchmark datasets. Items marked with \u2217 have results from Jeong et al. (2024). Adaptive-RAG (DistilBert) means we use DistilBert as classifier in Adaptive-RAG settings.***   `summary of some table`",
      "On the NQ dataset, our results are roughly on par with Adaptive-RAG, but with an increase in steps. This is because Adaptive-RAG, when constructing the dataset, set the condition that when zero, one, or multiple retrieval paths could yield the correct answer, the path requiring the fewest steps would be chosen as the correct label, with others marked as incorrect. However, this does not reflect reality as other paths can also yield correct answers."
    ],
    "response": "The performance variation between Adaptive-RAG, which uses T5-large, and the method utilizing DistilBERT can be attributed primarily to the significant difference in model size and capabilities. T5-large, with 770 million parameters, is much larger than DistilBERT, which has only 66 million parameters. This size difference means that T5-large has a greater capacity for understanding and processing complex datasets like HotpotQA, which features intricate question types that require extensive general knowledge.\n\nMoreover, while DistilBERT may not match T5-large in terms of knowledge capabilities, the MBA-RAG method, which employs a bandit approach for adaptive retrieval, has demonstrated more optimal strategy selection and lower step costs compared to Adaptive-RAG. This indicates that despite the smaller size of DistilBERT, the MBA-RAG method can balance performance and efficiency metrics effectively.\n\nIn summary, the larger model size and enhanced capabilities of T5-large likely contribute to its superior performance on complex datasets, while the efficiency and strategy selection of the MBA-RAG method provide a competitive advantage even with a smaller model like DistilBERT."
  },
  {
    "question": "Could you identify the title of the scholarly work that specifically addresses the topic of the multi-armed bandit problem, taking into account its decomposition and computational aspects?",
    "ground_truths": "The multi-armed bandit problem: decomposition and computation.",
    "reference": "1987. The multi-armed bandit problem: decomposition and computation. Mathematics of Operations Research , 12(2):262-268.Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.",
    "metadata": "complex",
    "retrieved_contexts": [
      "1987. The multi-armed bandit problem: decomposition and computation. Mathematics of Operations Research , 12(2):262-268.Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.",
      "References. Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023. Self-rag: Learning to retrieve, generate, and critique through self-reflection. Preprint , arXiv:2310.11511.Peter Auer. 2002. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research , 3(Nov):397-422.Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. 2002. Finite-time analysis of the multiarmed bandit problem. Machine learning , 47:235-256.Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, AdamsYu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei.",
      "The bandit framework requires only partial information for supervision; specifically, the model is supervised by the feedback of the chosen generation strategy, without indiscriminately penalizing the strategies that were not selected. This introduces greater flexibility by allowing the model to explore different generation strategies and obtain a more comprehensive selection.Second, to tackle the issue of inaccurate heuristic supervision of retrieval costs and the varying costs associated with different generation strategies, we design a dynamic, fine-grained reward function. This function penalizes inefficient generation strategies, even if they lead to correct results, ensuring that the model not only prioritizes accuracy but also optimizes computational efficiency.We evaluated our framework on both single-hop and multi-hop datasets. Results demonstrate that our method achieves SOTA generation accuracy while reducing retrieval costs by 20%.",
      "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn"
    ],
    "response": "The title of the scholarly work that specifically addresses the multi-armed bandit problem, focusing on its decomposition and computational aspects, is \"The multi-armed bandit problem: decomposition and computation.\" This work was published in the journal *Mathematics of Operations Research* in 1987, volume 12, issue 2, pages 262-268. \n\nThis information was derived from the context provided, which explicitly mentions the title and details of the publication."
  },
  {
    "question": "Under what conditions and for what reasons should one consider providing financial support to the Guardian, and how does this contribution affect its reporting capabilities and democratic engagement?",
    "ground_truths": "The purpose of supporting the Guardian financially is to power their reporting, allowing them to provide equal access to information, help people understand global events and their impact, demand better from the powerful, and fight for democracy.",
    "reference": "When access to information is made equal, greater numbers of people can understand global events and their impact on people and communities. Together, we can demand better from the powerful and fight for democracy.Whether you give a little or a lot, your funding will power our reporting for the years to come. Support the Guardian from as little as \u20ac1 - it only takes a minute. If you can, please consider giving a regular amount each month or year. Thank you. `Summary of some image`",
    "metadata": "complex",
    "retrieved_contexts": [
      "When access to information is made equal, greater numbers of people can understand global events and their impact on people and communities. Together, we can demand better from the powerful and fight for democracy.Whether you give a little or a lot, your funding will power our reporting for the years to come. Support the Guardian from as little as \u20ac1 - it only takes a minute. If you can, please consider giving a regular amount each month or year. Thank you. `Summary of some image`",
      "A new year means new opportunities, and we're hoping this year gives rise to some much-needed stability and progress. Whatever happens, the Guardian will be there, providing clarity and fearless, independent reporting from around the world, 24/7.Times are tough, and we know not everyone is in a position to pay for news. But as we're reader-funded, we rely on the ongoing generosity of those who can afford it. This vital support means millions can continue to read reliable reporting on the events shaping our world. Will you invest in the Guardian this year?Unlike many others, we have no billionaire owner, meaning we can fearlessly chase the truth and report it with integrity. 2023 will be no different; we will work with trademark determination and passion to bring you journalism that's always free from commercial or political interference. No one edits our editor or diverts our attention from what's most important.With your support, we'll continue to keep Guardian journalism open and free for everyone to read.",
      "After you have completed your play, the turn passes to the left. The tokens remain on the spaces qccupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time.According to the space your token reaches, you may be entitled  to buy real estate or other properties  or obliged  to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc.If you throw doubles, you move your token a s   usual, the sum of the two dice, and are subject to any privileges  or penalties pertaining  to the space on which you land. Retaining the dice, throw again and move your token a s   before.",
      "At least two years later, she published a version of the game through the Economic Game Company, a New York-based firm that counted Lizzie as a part-owner. The game became popular with leftwing intellectuals and on college campuses, and that popularity spread throughout the next three decades; it eventually caught on with a community of Quakers in Atlantic City, who customised it with the names of local neighbourhoods, and from there it found its way to Charles Darrow.In total, the game that Darrow brought to Parker Brothers has now sold hundreds of millions copies worldwide, and he received royalties throughout his life. ***Lizzy Magie's place in the game's folk history was lost for decades and ceded to the man who had picked it up at his friend's house - Charles Darrow. Photograph: AP***   `Summary of some image`   Lizzie was paid by Parker Brothers, too."
    ],
    "response": "One should consider providing financial support to the Guardian under several conditions and for specific reasons:\n\n1. **Access to Reliable Information**: Supporting the Guardian helps ensure that more people have access to reliable reporting on global events. This is crucial for fostering an informed public that can engage with and understand the complexities of current affairs.\n\n2. **Democratic Engagement**: Financial contributions enable the Guardian to maintain its independence from commercial and political influences. This independence is vital for fearless journalism that can hold power to account and promote democratic values.\n\n3. **Sustainability of Reporting**: Contributions, whether small or large, directly support the Guardian's ability to provide continuous and comprehensive news coverage. This is especially important in times of crisis or significant global events, where accurate reporting is essential.\n\n4. **Community Impact**: By supporting the Guardian, individuals contribute to a collective effort to demand better governance and accountability from those in power, which is fundamental to a functioning democracy.\n\nIn summary, financial support to the Guardian enhances its reporting capabilities by ensuring it remains independent and committed to delivering quality journalism. This, in turn, strengthens democratic engagement by empowering citizens with the information they need to participate actively in societal issues."
  },
  {
    "question": "What specific actions are required to be taken with the buildings situated on a color-group before you are allowed to proceed with selling any property within that color-group?",
    "ground_truths": "Buildings must be sold back to the Bank before the owner can sell any property of that color-group.",
    "reference": "Any buildings so located  must be  sold back to the Bank before the owner can sell any property  of that color-group.Houses and hotels may be  sold back to the Bank at any time for onehalf the price paid for them.All houses on one color-group must be sold one by one, evenly,  in reverse of the manner in which they were erected.All hotels on one color-group may be sold at once, or they may be sold one house at a time (one hotel equals five houses), evenly, in reverse of the manner in which they were erected.MORTGAGES: Unimproved properties can be mortgaged through the Bank at any time.",
    "metadata": "complex",
    "retrieved_contexts": [
      "Any buildings so located  must be  sold back to the Bank before the owner can sell any property  of that color-group.Houses and hotels may be  sold back to the Bank at any time for onehalf the price paid for them.All houses on one color-group must be sold one by one, evenly,  in reverse of the manner in which they were erected.All hotels on one color-group may be sold at once, or they may be sold one house at a time (one hotel equals five houses), evenly, in reverse of the manner in which they were erected.MORTGAGES: Unimproved properties can be mortgaged through the Bank at any time.",
      "If there are a limited number of houses and hotels available and two or more players wish to buy more than the B a n k  h a s ,   the houses or hotels must be  sold at auction to the highest bidder.SELLING PROPERN: Unimproved  properties, railroads and util~ties (but not buildings) may be sold to any player a s  a private transaction for any amount the owner can get;  however, no property can be sold to another player if buildings are standing on any properties of that colorgroup.",
      "T h e  next house you buy must be erected on one of the unimproved properties of this or any other complete  colorgroup you may own.The price you must pay the B a n k  for each house is shown on your ltle  Deed card for the property  on which you erect the house. `Summary of some image`   The owner still collects double rent from an opponent who lands on the unimproved properties of hisher complete  color-group.Following the above rules, you may buy and erect at any time a s many houses a s  your judgement and financial standing  will allow. But you must build evenly, i.e., you cannot erect more than one house on any one property  of any color-group until you have built one house on wery property of that group.",
      "Before an improved  property  can be mortgaged, all the buildings on all the properties  of its color-group must be sold back to the Bank at half price. The mortgage value is printed  on each Title Deed card.No rent can be collected on mortgaged  properties or utilities, but rent can be collected on unmortgaged properties in the same group.In order to lift the mortgage, the owner must pay the Bank the amount of the mortgage plus 10% interest. When all the propert~es of a color-group are no longer mortgaged, the owner may begin to buy back houses at full price."
    ],
    "response": "To sell any property within a color-group, you must first take specific actions regarding the buildings situated on that color-group. Here are the steps you need to follow:\n\n1. **Sell Buildings Back to the Bank**: All buildings (houses and hotels) located on the properties of the color-group must be sold back to the Bank before you can proceed with selling any property in that group.\n\n2. **Selling Houses**: Houses can be sold back to the Bank at any time for half the price you initially paid for them. However, you must sell them one by one and evenly, in the reverse order of how they were built.\n\n3. **Selling Hotels**: Hotels can be sold back to the Bank either all at once or one house at a time (noting that one hotel is equivalent to five houses). The same rule of selling evenly and in reverse order applies.\n\n4. **Mortgage Considerations**: If the properties are mortgaged, you must first sell all buildings on all properties of the color-group back to the Bank at half price before you can mortgage any improved property.\n\nThese steps ensure that you have cleared the buildings from the color-group, allowing you to proceed with selling the properties within that group."
  },
  {
    "question": "Under what specific conditions does the method demonstrate its performance on the 2wikiMultiHopQA dataset, and how does it compare to other datasets like MusiQue and HotpotQA?",
    "ground_truths": "Our method achieved significant improvements on the 2wikiMultiHopQA.",
    "reference": "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs.",
    "metadata": "complex",
    "retrieved_contexts": [
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs.",
      "This may be because, compared to Adaptive-RAG which uses T5-large (770M) as the classifier, our method uses DistilBERT (66M), which is 10 times smaller. Un- like the other two datasets, HotpotQA is a very challenging dataset with complex question types like actoid comparison questions that demand high general knowledge performance from the model.",
      "On the NQ dataset, our results are roughly on par with Adaptive-RAG, but with an increase in steps. This is because Adaptive-RAG, when constructing the dataset, set the condition that when zero, one, or multiple retrieval paths could yield the correct answer, the path requiring the fewest steps would be chosen as the correct label, with others marked as incorrect. However, this does not reflect reality as other paths can also yield correct answers.",
      "2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. 2024. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. Preprint , arXiv:2406.19215.Zhaofan Zhang, Yanan Xiao, Lu Jiang, Dingqi Yang, Minghao Yin, and Pengyang Wang. 2024. Spatialtemporal interplay in human mobility: A hierarchical reinforcement learning approach with hypergraph representation. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, pages 9396-9404."
    ],
    "response": "The method demonstrates its performance on the 2wikiMultiHopQA dataset under specific conditions that involve selecting retrieval paths based not only on the minimum steps but also on other feasible paths. This approach has led to a significant reduction in step costs of over 20%, indicating enhanced retrieval efficiency.\n\nWhen comparing the performance across different datasets:\n- On the **2wikiMultiHopQA**, the method shows significant improvements.\n- On the **MusiQue** dataset, the results are comparable to Adaptive-RAG, but with notably lower step costs, suggesting that the method is efficient in terms of retrieval costs while maintaining performance.\n- In contrast, on the **HotpotQA** dataset, the method slightly underperformed compared to Adaptive-RAG in terms of Exact Match (EM), Accuracy, and F1 scores, despite having lower step costs. This underperformance may be attributed to the complexity of HotpotQA, which includes challenging question types that require high general knowledge, and the fact that the method uses DistilBERT (66M) as the classifier, which is significantly smaller than the T5-large (770M) used by Adaptive-RAG.\n\nOverall, the method excels in efficiency on 2wikiMultiHopQA and MusiQue, while facing challenges on HotpotQA due to its complexity and the limitations of the model used."
  },
  {
    "question": "Could you elaborate on what HotpotQA is, including its purpose and the year it was first introduced, considering its relevance in the context of multi-hop question answering datasets?",
    "ground_truths": "HotpotQA is a dataset for diverse, explainable multi-hop question answering, introduced in 2018.",
    "reference": "2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. 2024. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. Preprint , arXiv:2406.19215.Zhaofan Zhang, Yanan Xiao, Lu Jiang, Dingqi Yang, Minghao Yin, and Pengyang Wang. 2024. Spatialtemporal interplay in human mobility: A hierarchical reinforcement learning approach with hypergraph representation. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, pages 9396-9404.",
    "metadata": "complex",
    "retrieved_contexts": [
      "2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. 2024. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. Preprint , arXiv:2406.19215.Zhaofan Zhang, Yanan Xiao, Lu Jiang, Dingqi Yang, Minghao Yin, and Pengyang Wang. 2024. Spatialtemporal interplay in human mobility: A hierarchical reinforcement learning approach with hypergraph representation. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, pages 9396-9404.",
      "3.1 Datasets. To demonstrate the performance of our method for queries of different complexities, following the work of Adaptive-RAG (Jeong et al., 2024), we selected three single-hop QA and three multi-hop QA datasets as our experimental datasets.For Single-hop QA, we choose SquAD v1.1 (Rajpurkar et al., 2016), Natural Questions (Kwiatkowski et al., 2019) and TriviaQA (Joshi et al., 2017). These datasets consist of each query and its related articles that contain the answers.For Multi-hop QA, we choose MuSiQue (Trivedi et al., 2022b), HotpotQA (Yang et al., 2018) and 2WikiMultiHopQA (Ho et al., 2020). For these multi-hop datasets, the answers cannot be directly obtained and require multi-step reasoning based on the information in the articles to arrive at the final answer.",
      "2017. TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1601-1611, Vancouver, Canada. Association for Computational Linguistics.Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick SH Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In EMNLP (1) , pages 6769-6781.Michael N Katehakis and Arthur F Veinott Jr.",
      "This may be because, compared to Adaptive-RAG which uses T5-large (770M) as the classifier, our method uses DistilBERT (66M), which is 10 times smaller. Un- like the other two datasets, HotpotQA is a very challenging dataset with complex question types like actoid comparison questions that demand high general knowledge performance from the model."
    ],
    "response": "HotpotQA is a dataset specifically designed for multi-hop question answering, which involves answering questions that require synthesizing information from multiple sources or passages. It was first introduced in 2018. The dataset is notable for its complexity, featuring diverse question types, including those that necessitate a high level of general knowledge and reasoning ability from models.\n\nThe purpose of HotpotQA is to advance the field of question answering by providing a challenging benchmark that encourages the development of models capable of understanding and integrating information from various contexts to arrive at accurate answers. This makes it particularly relevant in the context of multi-hop question answering datasets, as it tests the ability of AI systems to perform reasoning across different pieces of information."
  },
  {
    "question": "In the context of the MAB algorithm, what are the specific reward values assigned to each retrieval strategy for the single-hop dataset, considering that the rewards must balance both performance and efficiency?",
    "ground_truths": "For the single-hop dataset, the rewards are set at 1, 0.9, and 1-step/10 respectively for the three retrieval strategies 'zero,' 'one,' and 'multiple,'. When none of the three options can answer the question, the reward is set to -1.",
    "reference": "A.2 Reward Setting. For single-hop and multi-hop datasets, due to the differences in their tendencies for retrieval strategy selection, the single-hop dataset tends to choose the 'zero' and 'one' retrieval strategies, while the multi-hop dataset favors the 'one' and 'multiple' strategies. Therefore, for the MAB algorithm, the same set of rewards cannot achieve optimal results on both types of datasets simultaneously. Motivated by (Zhang et al., 2024), during our experiments, we set two different groups of reward settings.For the single-hop dataset, we adopted a dynamic reward approach, combining strategy selection with step costs to balance performance and efficiency, the rewards are set at 1, 0.9, and 1-step/10 respectively for the three retrieval strategies 'zero,' 'one,' and 'multiple,'. When none of the three options can answer the question, the reward is set to -1.For the multi-hop dataset, rewards are set at 4.3, 2.3, and 1.15.",
    "metadata": "complex",
    "retrieved_contexts": [
      "A.2 Reward Setting. For single-hop and multi-hop datasets, due to the differences in their tendencies for retrieval strategy selection, the single-hop dataset tends to choose the 'zero' and 'one' retrieval strategies, while the multi-hop dataset favors the 'one' and 'multiple' strategies. Therefore, for the MAB algorithm, the same set of rewards cannot achieve optimal results on both types of datasets simultaneously. Motivated by (Zhang et al., 2024), during our experiments, we set two different groups of reward settings.For the single-hop dataset, we adopted a dynamic reward approach, combining strategy selection with step costs to balance performance and efficiency, the rewards are set at 1, 0.9, and 1-step/10 respectively for the three retrieval strategies 'zero,' 'one,' and 'multiple,'. When none of the three options can answer the question, the reward is set to -1.For the multi-hop dataset, rewards are set at 4.3, 2.3, and 1.15.",
      "The bandit framework requires only partial information for supervision; specifically, the model is supervised by the feedback of the chosen generation strategy, without indiscriminately penalizing the strategies that were not selected. This introduces greater flexibility by allowing the model to explore different generation strategies and obtain a more comprehensive selection.Second, to tackle the issue of inaccurate heuristic supervision of retrieval costs and the varying costs associated with different generation strategies, we design a dynamic, fine-grained reward function. This function penalizes inefficient generation strategies, even if they lead to correct results, ensuring that the model not only prioritizes accuracy but also optimizes computational efficiency.We evaluated our framework on both single-hop and multi-hop datasets. Results demonstrate that our method achieves SOTA generation accuracy while reducing retrieval costs by 20%.",
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs.",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results."
    ],
    "response": "For the single-hop dataset in the context of the MAB (Multi-Armed Bandit) algorithm, the specific reward values assigned to each retrieval strategy are as follows:\n\n- **Zero strategy**: Reward of **1**\n- **One strategy**: Reward of **0.9**\n- **Multiple strategy**: Reward of **1-step/10** (which indicates a dynamic reward based on the step cost)\n\nAdditionally, if none of the strategies can answer the question, the reward is set to **-1**.\n\nThese rewards are designed to balance both performance and efficiency, allowing the algorithm to optimize its strategy selection effectively. The approach taken is dynamic, combining strategy selection with step costs to ensure that the model not only focuses on accuracy but also on computational efficiency. \n\nThis information was derived from the context provided regarding the reward settings for the single-hop dataset in the MAB algorithm."
  },
  {
    "question": "Under what specific influence did Lizzie create her game design that incorporates elements of taxation, and how does it reflect her political beliefs or inspirations?",
    "ground_truths": "Lizzie's game design was inspired by the ideas of the economist Henry George, who advocated for putting the burden of taxation on wealthy landowners.",
    "reference": "In one corner were the Poor House and the Public Park, and across the board was the Jail. Another corner contained an image of the globe and an homage to Lizzie's political hero, the economist Henry George, whose ideas about putting the burden of taxation on wealthy landowners inspired the game: 'Labor upon Mother Earth Produces Wages.' Also included on the board were three words that have endured for more than a century after Lizzie scrawled them there: GO TO JAIL.Lizzie drew nine rectangular spaces along the edges of the board between each set of corners. In the centre of each nine-space grouping was a railroad, with spaces for rent or sale on either side.",
    "metadata": "complex",
    "retrieved_contexts": [
      "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies. However, and of course unbeknownst to Lizzie at the time, it was the monopolist rules that would later capture the public's imagination.After years of tinkering, writing and pondering her new creation, Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
      "In one corner were the Poor House and the Public Park, and across the board was the Jail. Another corner contained an image of the globe and an homage to Lizzie's political hero, the economist Henry George, whose ideas about putting the burden of taxation on wealthy landowners inspired the game: 'Labor upon Mother Earth Produces Wages.' Also included on the board were three words that have endured for more than a century after Lizzie scrawled them there: GO TO JAIL.Lizzie drew nine rectangular spaces along the edges of the board between each set of corners. In the centre of each nine-space grouping was a railroad, with spaces for rent or sale on either side.",
      "The Landlord's Game. Photograph: Tom Forsyth. Lizzie's game featured play money and deeds and properties that could be bought and sold. Players borrowed money, either from the bank or from each other, and they had to pay taxes. And it featured a path that allowed players to circle the board - in contrast to the linear-path design used by many games at the time.",
      "Serving out their time meant waiting until they threw a double. 'The rallying and chaffing of the others when one player finds himself an inmate of the jail, and the expressions of mock sympathy and condolence when one is obliged to betake himself to the poor house, make a large part of the fun and merriment of the game,' Lizzie said.From its inception, the Landlord's Game aimed to seize on the natural human instinct to compete. And, somewhat surprisingly, Lizzie created two sets of rules: an anti-monopolist set in which all were rewarded when wealth was created, and a monopolist set in which the goal was to create monopolies and crush opponents."
    ],
    "response": "Lizzie created her game design, known as the Landlord's Game, under the influence of her political hero, economist Henry George. His ideas focused on taxing wealthy landowners, which is reflected in the game's incorporation of taxation elements. The game features spaces for players to pay taxes and includes properties that can be bought and sold, emphasizing economic interactions and the consequences of wealth distribution.\n\nThe design of the game also embodies a dualism, showcasing a tension between different economic philosophies. While Lizzie's original vision aimed to critique monopolistic practices, it inadvertently laid the groundwork for a game that would later captivate players with its monopolistic rules. This complexity in her design reflects her political beliefs and inspirations, particularly her commitment to addressing social and economic inequalities.\n\nIn summary, Lizzie's game design was significantly influenced by Henry George's taxation principles, which shaped the game's mechanics and underlying message about wealth and social responsibility."
  },
  {
    "question": "In the context of the multi-armed bandit framework, what strategy is employed to balance exploration and exploitation, particularly when considering scenarios where financial constraints, such as interest payments on mortgages, might affect decision-making?",
    "ground_truths": "An epsilon-greedy strategy is used to balance the trade-off between exploration and exploitation.",
    "reference": "2.2 Query Encoding and Arm Selection. To overcome the limitations of attributing each query to a single generation method, we reformulate the generation selection as a trial-and-error reinforcement learning problem, where each generation method is treated as an action (i.e. an arm) in a multi-armed bandit framework.We employ DistilBERT, a lightweight pretrained language model (PLM), to encode user queries, generating an action distribution z = f \u03b8 ( x ) . Directly supervising this output could cause the system to overly favor a single generation method, leading to sub-optimal local convergence.To prevent this, we incorporate an epsilongreedy strategy (Langford and Zhang, 2007) to balance the trade-off between exploration and exploitation (Auer, 2002; Auer et al., 2002). This ensures that the system primarily utilizes the bestperforming generation methods while still exploring other options to improve long-term performance. Specifically, the 'arm' is chosen as a = arg max( z ) with probability 1 -\u03f5 , or a random generation method with probability \u03f5 .",
    "metadata": "distracting element",
    "retrieved_contexts": [
      "1987. The multi-armed bandit problem: decomposition and computation. Mathematics of Operations Research , 12(2):262-268.Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.",
      "The bandit framework requires only partial information for supervision; specifically, the model is supervised by the feedback of the chosen generation strategy, without indiscriminately penalizing the strategies that were not selected. This introduces greater flexibility by allowing the model to explore different generation strategies and obtain a more comprehensive selection.Second, to tackle the issue of inaccurate heuristic supervision of retrieval costs and the varying costs associated with different generation strategies, we design a dynamic, fine-grained reward function. This function penalizes inefficient generation strategies, even if they lead to correct results, ensuring that the model not only prioritizes accuracy but also optimizes computational efficiency.We evaluated our framework on both single-hop and multi-hop datasets. Results demonstrate that our method achieves SOTA generation accuracy while reducing retrieval costs by 20%.",
      "2.2 Query Encoding and Arm Selection. To overcome the limitations of attributing each query to a single generation method, we reformulate the generation selection as a trial-and-error reinforcement learning problem, where each generation method is treated as an action (i.e. an arm) in a multi-armed bandit framework.We employ DistilBERT, a lightweight pretrained language model (PLM), to encode user queries, generating an action distribution z = f \u03b8 ( x ) . Directly supervising this output could cause the system to overly favor a single generation method, leading to sub-optimal local convergence.To prevent this, we incorporate an epsilongreedy strategy (Langford and Zhang, 2007) to balance the trade-off between exploration and exploitation (Auer, 2002; Auer et al., 2002). This ensures that the system primarily utilizes the bestperforming generation methods while still exploring other options to improve long-term performance. Specifically, the 'arm' is chosen as a = arg max( z ) with probability 1 -\u03f5 , or a random generation method with probability \u03f5 .",
      "Limitations. Our reinforcement learning-based approach for adaptive retrieval in language models demonstrates promising results; however, it is not without limitations. The framework's dependence on the specific structure of the multi-armed bandit algorithm can introduce challenges in scalability and adaptability to new, unseen query types. Future work could explore more efficient algorithms that maintain performance while reducing computational demands."
    ],
    "response": "In the multi-armed bandit framework, balancing exploration and exploitation is crucial, especially in scenarios influenced by financial constraints, such as interest payments on mortgages. A common strategy employed to achieve this balance involves using a dynamic reward function that not only focuses on the accuracy of the chosen strategies but also incorporates the costs associated with them.\n\nThis approach allows the model to explore various generation strategies while penalizing those that are inefficient, even if they yield correct results. By doing so, it ensures that the decision-making process is not solely based on immediate rewards (exploitation) but also considers the long-term implications of different strategies (exploration). This is particularly relevant in financial contexts, where the costs of decisions can significantly impact overall outcomes.\n\nThe context also highlights that the model is supervised by feedback from the chosen strategies, which adds flexibility and encourages the exploration of different options without harsh penalties for unselected strategies. This can be beneficial when financial constraints are a factor, as it allows for a more comprehensive evaluation of potential decisions.\n\nIn summary, the strategy involves a dynamic reward function that balances the need for accurate results with the necessity of optimizing costs, thereby addressing both exploration and exploitation in decision-making under financial constraints."
  },
  {
    "question": "In the context of multi-label classification setups, what approach was implemented to improve the classification choice while ensuring that step costs were minimized?",
    "ground_truths": "A multi-label classification setup was implemented, treating all retrieval strategies that could yield the correct answer as correct labels.",
    "reference": "Therefore, to make the classification choice more rational while considering step costs, we implemented a multi-label classification setup, treating all retrieval strategies that could yield the correct answer as correct labels. We trained the classification model to predict multiple potential labels and selected the most likely label during the final inference.",
    "metadata": "distracting element",
    "retrieved_contexts": [
      "Therefore, to make the classification choice more rational while considering step costs, we implemented a multi-label classification setup, treating all retrieval strategies that could yield the correct answer as correct labels. We trained the classification model to predict multiple potential labels and selected the most likely label during the final inference.",
      "A.4 Results. The experimental results show that classifiers trained with multi-labels are highly prone to overfitting. Due to the high proportion of the 'multiple' labels, the final model tends to exclusively choose 'multiple.' While this achieves good performance in metrics, the step cost is excessively high, even for single-step datasets. Such choices are overly inefficient. In contrast, our MBA-RAG is essentially a form of multi-label classification, and the dynamic reward settings enable the model to make the most rational choices based on the combination of step costs, making it more practical and feasible.Although the Adaptive-RAG-MultiLabel yields generally high results, this is because, under this training mode, the model ultimately opts for 'multiple' labels. During the construction of the training set, a large number of samples are tagged with multiple labels, leading the model to completely overfit on the 'multiple' label after training. However, this approach results in an excessively high number of steps, and most problems do not require multi-step retrieval.",
      "A.3.1 Setting. In the experimental setup, for the Multi-label classifier, we maintained consistency with the AdaptiveRAG's model setting, using T5-large as the classifier and modifying the model to a multi-label classification head. The learning rate was set to 1e-4. We employ multi-label training and use single-label form for inference, ultimately selecting retrieval generation according to the corresponding retrieval strategy. The experimental results are shown in Tables 4 and 3. ***Table 4: Averaged results of multi-label classification on a collection of benchmark datasets including single-hop and multi-hop queries.***   `summary of some table`",
      "A.3 Multi-label Classification. Due to Adaptive-RAG defining the selection of retrieval strategies as a single-label classification problem, where multiple strategies can yield correct results, it selects the strategy with the fewest   ***Table 3: Results of multi-label classification on each of a collection of datasets with FLAN-T5-XL (3B) as the LLM.***   `summary of some table`   steps as the correct label, treating other choices as incorrect. This approach is somewhat unreasonable because the other choices are also correct, albeit with a higher step cost."
    ],
    "response": "In the context of multi-label classification setups, an approach was implemented that involved treating all retrieval strategies capable of yielding the correct answer as valid labels. This method allowed the classification model to predict multiple potential labels, and during the final inference, the model selected the most likely label.\n\nHowever, it was noted that classifiers trained with multi-labels were prone to overfitting, particularly due to a high proportion of instances labeled as 'multiple.' This tendency led the model to predominantly choose the 'multiple' label, which, while achieving good performance metrics, resulted in excessively high step costs, especially for single-step datasets. \n\nTo address this inefficiency, the MBA-RAG approach was introduced, which functions as a form of multi-label classification but incorporates dynamic reward settings. This enables the model to make more rational choices by considering the combination of step costs, making the classification process more practical and feasible.\n\nIn summary, the key steps involved were:\n1. Implementing a multi-label classification setup to predict multiple labels.\n2. Using dynamic reward settings to rationalize classification choices while minimizing step costs.\n3. Transitioning from multi-label training to single-label inference to reduce overfitting and step costs.\n\nThis approach aimed to balance the need for accurate classification with the efficiency of the retrieval process."
  },
  {
    "question": "In the context of ensuring a fair evaluation of multi-hop QA systems, which datasets were chosen for the study, particularly considering the potential biases in retrieval strategies?",
    "ground_truths": "For Multi-hop QA, the selected datasets are MuSiQue, HotpotQA, and 2WikiMultiHopQA.",
    "reference": "3.1 Datasets. To demonstrate the performance of our method for queries of different complexities, following the work of Adaptive-RAG (Jeong et al., 2024), we selected three single-hop QA and three multi-hop QA datasets as our experimental datasets.For Single-hop QA, we choose SquAD v1.1 (Rajpurkar et al., 2016), Natural Questions (Kwiatkowski et al., 2019) and TriviaQA (Joshi et al., 2017). These datasets consist of each query and its related articles that contain the answers.For Multi-hop QA, we choose MuSiQue (Trivedi et al., 2022b), HotpotQA (Yang et al., 2018) and 2WikiMultiHopQA (Ho et al., 2020). For these multi-hop datasets, the answers cannot be directly obtained and require multi-step reasoning based on the information in the articles to arrive at the final answer.",
    "metadata": "distracting element",
    "retrieved_contexts": [
      "3.1 Datasets. To demonstrate the performance of our method for queries of different complexities, following the work of Adaptive-RAG (Jeong et al., 2024), we selected three single-hop QA and three multi-hop QA datasets as our experimental datasets.For Single-hop QA, we choose SquAD v1.1 (Rajpurkar et al., 2016), Natural Questions (Kwiatkowski et al., 2019) and TriviaQA (Joshi et al., 2017). These datasets consist of each query and its related articles that contain the answers.For Multi-hop QA, we choose MuSiQue (Trivedi et al., 2022b), HotpotQA (Yang et al., 2018) and 2WikiMultiHopQA (Ho et al., 2020). For these multi-hop datasets, the answers cannot be directly obtained and require multi-step reasoning based on the information in the articles to arrive at the final answer.",
      "A.2 Reward Setting. For single-hop and multi-hop datasets, due to the differences in their tendencies for retrieval strategy selection, the single-hop dataset tends to choose the 'zero' and 'one' retrieval strategies, while the multi-hop dataset favors the 'one' and 'multiple' strategies. Therefore, for the MAB algorithm, the same set of rewards cannot achieve optimal results on both types of datasets simultaneously. Motivated by (Zhang et al., 2024), during our experiments, we set two different groups of reward settings.For the single-hop dataset, we adopted a dynamic reward approach, combining strategy selection with step costs to balance performance and efficiency, the rewards are set at 1, 0.9, and 1-step/10 respectively for the three retrieval strategies 'zero,' 'one,' and 'multiple,'. When none of the three options can answer the question, the reward is set to -1.For the multi-hop dataset, rewards are set at 4.3, 2.3, and 1.15.",
      "On the NQ dataset, our results are roughly on par with Adaptive-RAG, but with an increase in steps. This is because Adaptive-RAG, when constructing the dataset, set the condition that when zero, one, or multiple retrieval paths could yield the correct answer, the path requiring the fewest steps would be chosen as the correct label, with others marked as incorrect. However, this does not reflect reality as other paths can also yield correct answers.",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results."
    ],
    "response": "For the study on the evaluation of multi-hop QA systems, the selected datasets included three single-hop QA datasets and three multi-hop QA datasets. The single-hop QA datasets chosen were:\n\n1. **SquAD v1.1** (Rajpurkar et al., 2016)\n2. **Natural Questions** (Kwiatkowski et al., 2019)\n3. **TriviaQA** (Joshi et al., 2017)\n\nFor the multi-hop QA datasets, the selections were:\n\n1. **MuSiQue** (Trivedi et al., 2022b)\n2. **HotpotQA** (Yang et al., 2018)\n3. **2WikiMultiHopQA** (Ho et al., 2020)\n\nThese datasets were chosen to demonstrate the performance of the method across queries of varying complexities, particularly considering the biases in retrieval strategies. The single-hop datasets typically utilize 'zero' and 'one' retrieval strategies, while the multi-hop datasets tend to favor 'one' and 'multiple' strategies. This distinction in retrieval strategy tendencies was a key consideration in the study."
  },
  {
    "question": "In the context of the game, what are the specific methods available to a player for getting out of jail, considering the rules established by the 2017 TriviaQA dataset challenge?",
    "ground_truths": "The ways to get out of jail are: (1) throwing doubles on any of your next three turns; (2) using the 'Get Out of Jail Free' card if you have it; (3) purchasing the 'Get Out of Jail Free' card from another player and playing it; (4) paying a fine of $50 before you roll the dice on either of your next two turns.",
    "reference": ".(I) throwing doubles on any of your next three turns;  if you succeed in doing this you immediately  move forward the number of spaces shown by  your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3)  purchasing  the \"Get Out of Jail Free\" card from another player and playing it; (4)  paying a fine of $50 before  you roll the dice on either of your next two turns.If  you do not throw doubles by  your third turn, you must pay the $50 fine. Y o u  then get out of Jail and immediately move forward the number of spaces shown by  your throw.Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\" F R E E  P A R K I N G \" :  A player landing on this place does not receive any money, property or reward of any kind. This is just a \"free\" resting place.HOUSES: When you own all the propert~es in a color-group you may buy houses from the B a n k  and erect them on those properties.If  you buy one house, you may put it on any one of those properties.",
    "metadata": "distracting element",
    "retrieved_contexts": [
      ".(I) throwing doubles on any of your next three turns;  if you succeed in doing this you immediately  move forward the number of spaces shown by  your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3)  purchasing  the \"Get Out of Jail Free\" card from another player and playing it; (4)  paying a fine of $50 before  you roll the dice on either of your next two turns.If  you do not throw doubles by  your third turn, you must pay the $50 fine. Y o u  then get out of Jail and immediately move forward the number of spaces shown by  your throw.Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\" F R E E  P A R K I N G \" :  A player landing on this place does not receive any money, property or reward of any kind. This is just a \"free\" resting place.HOUSES: When you own all the propert~es in a color-group you may buy houses from the B a n k  and erect them on those properties.If  you buy one house, you may put it on any one of those properties.",
      ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
      "Serving out their time meant waiting until they threw a double. 'The rallying and chaffing of the others when one player finds himself an inmate of the jail, and the expressions of mock sympathy and condolence when one is obliged to betake himself to the poor house, make a large part of the fun and merriment of the game,' Lizzie said.From its inception, the Landlord's Game aimed to seize on the natural human instinct to compete. And, somewhat surprisingly, Lizzie created two sets of rules: an anti-monopolist set in which all were rewarded when wealth was created, and a monopolist set in which the goal was to create monopolies and crush opponents.",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when."
    ],
    "response": "In the game, there are several specific methods available for a player to get out of jail:\n\n1. **Throwing Doubles**: You can get out of jail by rolling doubles on any of your next three turns. If you succeed, you move forward the number of spaces shown by your doubles throw, but you do not get another turn.\n\n2. **Get Out of Jail Free Card**: If you possess a \"Get Out of Jail Free\" card, you can use it to get out of jail.\n\n3. **Purchasing the Card**: You can buy a \"Get Out of Jail Free\" card from another player and then use it.\n\n4. **Paying a Fine**: You can pay a fine of $50 before rolling the dice on either of your next two turns. If you do not roll doubles by your third turn, you must pay the $50 fine to get out of jail and then move forward based on your next roll.\n\nThese methods provide players with various options to escape jail while continuing their gameplay."
  },
  {
    "question": "In the context of ensuring financial stability, could you specify which model and learning rate were employed for the Multi-label classifier in the experimental setup?",
    "ground_truths": "The T5-large model was used as the classifier with a learning rate of 1e-4.",
    "reference": "A.3.1 Setting. In the experimental setup, for the Multi-label classifier, we maintained consistency with the AdaptiveRAG's model setting, using T5-large as the classifier and modifying the model to a multi-label classification head. The learning rate was set to 1e-4. We employ multi-label training and use single-label form for inference, ultimately selecting retrieval generation according to the corresponding retrieval strategy. The experimental results are shown in Tables 4 and 3. ***Table 4: Averaged results of multi-label classification on a collection of benchmark datasets including single-hop and multi-hop queries.***   `summary of some table`",
    "metadata": "distracting element",
    "retrieved_contexts": [
      "A.3.1 Setting. In the experimental setup, for the Multi-label classifier, we maintained consistency with the AdaptiveRAG's model setting, using T5-large as the classifier and modifying the model to a multi-label classification head. The learning rate was set to 1e-4. We employ multi-label training and use single-label form for inference, ultimately selecting retrieval generation according to the corresponding retrieval strategy. The experimental results are shown in Tables 4 and 3. ***Table 4: Averaged results of multi-label classification on a collection of benchmark datasets including single-hop and multi-hop queries.***   `summary of some table`",
      "Therefore, to make the classification choice more rational while considering step costs, we implemented a multi-label classification setup, treating all retrieval strategies that could yield the correct answer as correct labels. We trained the classification model to predict multiple potential labels and selected the most likely label during the final inference.",
      "A.4 Results. The experimental results show that classifiers trained with multi-labels are highly prone to overfitting. Due to the high proportion of the 'multiple' labels, the final model tends to exclusively choose 'multiple.' While this achieves good performance in metrics, the step cost is excessively high, even for single-step datasets. Such choices are overly inefficient. In contrast, our MBA-RAG is essentially a form of multi-label classification, and the dynamic reward settings enable the model to make the most rational choices based on the combination of step costs, making it more practical and feasible.Although the Adaptive-RAG-MultiLabel yields generally high results, this is because, under this training mode, the model ultimately opts for 'multiple' labels. During the construction of the training set, a large number of samples are tagged with multiple labels, leading the model to completely overfit on the 'multiple' label after training. However, this approach results in an excessively high number of steps, and most problems do not require multi-step retrieval.",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results."
    ],
    "response": "In the experimental setup for the Multi-label classifier aimed at ensuring financial stability, the model used was T5-large, which was adapted to include a multi-label classification head. The learning rate for this model was set to 1e-4. \n\nThis information was derived from the context that detailed the model settings and training approach for the classifier."
  },
  {
    "question": "Considering the tendency to remember only one successful approach in a field with multiple contributors, what is the flaw in Adaptive-RAG's method for choosing retrieval strategies?",
    "ground_truths": "Adaptive-RAG defines the selection of retrieval strategies as a single-label classification problem, which is somewhat unreasonable because it treats other correct choices as incorrect if they have a higher step cost, even though multiple strategies can yield correct results.",
    "reference": "A.3 Multi-label Classification. Due to Adaptive-RAG defining the selection of retrieval strategies as a single-label classification problem, where multiple strategies can yield correct results, it selects the strategy with the fewest   ***Table 3: Results of multi-label classification on each of a collection of datasets with FLAN-T5-XL (3B) as the LLM.***   `summary of some table`   steps as the correct label, treating other choices as incorrect. This approach is somewhat unreasonable because the other choices are also correct, albeit with a higher step cost.",
    "metadata": "distracting element",
    "retrieved_contexts": [
      "Simple queries may incur unnecessary computational overhead when complex retrieval strategies are used, while complex, multi-step queries may not be adequately addressed. To tackle this issue, AdaptiveRAG introduces an adaptive router that selects the retrieval method based on the complexity of the query. However, AdaptiveRAG simplifies the retrieval strategy into a single-choice task by using heuristic supervision that favors only one process with the least retrieval cost. This supervision is inaccurate for two main reasons.",
      "However, this approach may hinder the versatility of language models or introduce unnecessary or off-topic* Equally contributed authors\u2020 Corresponding authorpassages. To address this issue, methods such as SEAKR (Yao et al., 2024) and FLARE (Jiang et al., 2023) have been designed to perform active retrieval only when necessary.Furthermore, AdaptiveRAG (Jeong et al., 2024) argues that real-world queries often vary in difficulty, such as the number of reasoning steps required or the depth of information needed to answer a query. Thus, applying a single retrieval method across all queries can be ineffective.",
      "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results."
    ],
    "response": "The flaw in Adaptive-RAG's method for choosing retrieval strategies lies in its simplification of the retrieval process into a single-choice task. This approach uses heuristic supervision that tends to favor only one retrieval process based on the least retrieval cost. This can lead to inaccuracies for two main reasons:\n\n1. **Overhead for Simple Queries**: When complex retrieval strategies are applied to simple queries, it incurs unnecessary computational overhead.\n2. **Inadequate Handling of Complex Queries**: Conversely, complex, multi-step queries may not be sufficiently addressed by this single-choice method.\n\nAs a result, while Adaptive-RAG aims to optimize retrieval efficiency, its reliance on a single heuristic can overlook other feasible paths that might be more effective for certain queries. This limitation can hinder its overall performance, especially in scenarios where multiple retrieval strategies could yield better results."
  },
  {
    "question": "In the context of building houses on properties, what are the consequences if your token lands on the 'Go to Jail' space in the game, considering you cannot collect rent or make property improvements while in Jail?",
    "ground_truths": "When your token lands on the space marked 'Go to Jail', you must move it directly into Jail and cannot collect your $200 salary in that move. Your turn ends when you are sent to Jail.",
    "reference": ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
    "metadata": "distracting element",
    "retrieved_contexts": [
      ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      "After you have completed your play, the turn passes to the left. The tokens remain on the spaces qccupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time.According to the space your token reaches, you may be entitled  to buy real estate or other properties  or obliged  to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc.If you throw doubles, you move your token a s   usual, the sum of the two dice, and are subject to any privileges  or penalties pertaining  to the space on which you land. Retaining the dice, throw again and move your token a s   before.",
      ".(I) throwing doubles on any of your next three turns;  if you succeed in doing this you immediately  move forward the number of spaces shown by  your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3)  purchasing  the \"Get Out of Jail Free\" card from another player and playing it; (4)  paying a fine of $50 before  you roll the dice on either of your next two turns.If  you do not throw doubles by  your third turn, you must pay the $50 fine. Y o u  then get out of Jail and immediately move forward the number of spaces shown by  your throw.Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\" F R E E  P A R K I N G \" :  A player landing on this place does not receive any money, property or reward of any kind. This is just a \"free\" resting place.HOUSES: When you own all the propert~es in a color-group you may buy houses from the B a n k  and erect them on those properties.If  you buy one house, you may put it on any one of those properties."
    ],
    "response": "If your token lands on the \"Go to Jail\" space in the game, you will be sent directly to Jail, and your turn will end immediately. This means you cannot collect your $200 salary for that turn. While in Jail, you are unable to collect rent or make property improvements, which can significantly impact your strategy and financial situation in the game.\n\nTo get out of Jail, you have a few options:\n1. You can throw doubles on any of your next three turns. If you succeed, you will move forward the number of spaces indicated by your roll, but you do not get another turn.\n2. You can use a \"Get Out of Jail Free\" card if you have one.\n3. You can purchase a \"Get Out of Jail Free\" card from another player.\n4. You can pay a fine of $50 before rolling the dice on either of your next two turns. If you do not roll doubles by your third turn, you must pay the $50 fine to get out of Jail.\n\nWhile in Jail, you still have the ability to buy and sell properties, as well as buy and sell houses and hotels, and collect rents, which can help mitigate some of the disadvantages of being unable to move around the board. \n\nThis information was derived from the context regarding the rules of the game related to landing on the \"Go to Jail\" space and the consequences that follow."
  },
  {
    "question": "Considering the context of retrieval-augmented generation and its effectiveness, could you tell me what games are depicted in the picture accompanying the Evening Star article?",
    "ground_truths": "The games mentioned are the Landlord's Game and another game with the word MONOPOLY written across its center four times in bold black letters, along with the 'Darrow' board from the Parker Brothers box.",
    "reference": "In a picture accompanying the Evening Star piece, she held up game boards from the Landlord's Game and another game that had the word MONOPOLY written across its center four times in bold black letters; on the table in front of her was the now-familiar 'Darrow' board, fresh out of the Parker Brothers box. The image of Lizzie painted by the reporter couldn't have been clearer.",
    "metadata": "distracting element",
    "retrieved_contexts": [
      "1 Introduction and Related Work. Retrieval Augmented Generation (Lewis et al., 2020) has shown significant promise in addressing knowledge-intensive natural language processing (NLP) tasks by integrating an updated knowledge base with a language model. This combination allows language model to access up-to-date knowledge, improving their faithfulness and reducing hallucinations.Most existing RAG frameworks employ a retrieve-and-generate setup that indiscriminately performs retrieval based on the input.",
      "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn",
      "1998. Reinforcement learning: An introduction. IEEE Transactions on Neural Networks , 9(5):1054-1054. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022a. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint arXiv:2212.10509 .Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022b. MuSiQue: Multihop questions via single-hop question composition. Transactions of the Association for Computational Linguistics , 10:539-554.Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning.",
      "2024. DRAGIN: Dynamic retrieval augmented generation based on the real-time information needs of large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 12991-13013, Bangkok, Thailand. Association for Computational Linguistics.Weigao Sun, Zhen Qin, Dong Li, Xuyang Shen, Yu Qiao, and Yiran Zhong. 2024a. Linear attention sequence parallelism. arXiv preprint arXiv:2404.02882 .Weigao Sun, Zhen Qin, Weixuan Sun, Shidi Li, Dong Li, Xuyang Shen, Yu Qiao, and Yiran Zhong. 2024b. Co2: Efficient distributed training with full communication-computation overlap. arXiv preprint arXiv:2401.16265 . - R.S. Sutton and A.G. Barto."
    ],
    "response": "The picture accompanying the Evening Star article depicts game boards from two games: the Landlord's Game and another game prominently featuring the word \"MONOPOLY\" written across its center. Additionally, there is a 'Darrow' board from Parker Brothers visible on the table in front of Lizzie Magie, who is holding up the game boards.\n\nThis information was derived from the context that specifically mentions the games and their visual representation in the article."
  },
  {
    "question": "Hi, I'm working on a research paper about neural information processing and question answering benchmarks. Could you tell me what the title of the 2019 benchmark for question answering research is?",
    "ground_truths": "Natural questions: A benchmark for question answering research.",
    "reference": "2019. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics , 7:452-466.John Langford and Tong Zhang. 2007. The epochgreedy algorithm for multi-armed bandits with side information. Advances in neural information processing systems , 20.Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, et al.",
    "metadata": "situational",
    "retrieved_contexts": [
      "2019. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics , 7:452-466.John Langford and Tong Zhang. 2007. The epochgreedy algorithm for multi-armed bandits with side information. Advances in neural information processing systems , 20.Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, et al.",
      "1998. Reinforcement learning: An introduction. IEEE Transactions on Neural Networks , 9(5):1054-1054. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022a. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint arXiv:2212.10509 .Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022b. MuSiQue: Multihop questions via single-hop question composition. Transactions of the Association for Computational Linguistics , 10:539-554.Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning.",
      "2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems , 33:9459-9474.Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023. When not to trust language models: Investigating effectiveness of parametric and non-parametric memories. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 9802-9822, Toronto, Canada. Association for Computational Linguistics.Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing , pages 2383-2392, Austin, Texas. Association for Computational Linguistics.Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2020. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. Preprint , arXiv:1910.01108.Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, and Yiqun Liu.",
      "2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. 2024. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. Preprint , arXiv:2406.19215.Zhaofan Zhang, Yanan Xiao, Lu Jiang, Dingqi Yang, Minghao Yin, and Pengyang Wang. 2024. Spatialtemporal interplay in human mobility: A hierarchical reinforcement learning approach with hypergraph representation. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, pages 9396-9404."
    ],
    "response": "The title of the 2019 benchmark for question answering research is \"Natural Questions: A benchmark for question answering research.\" This benchmark was published in the Transactions of the Association for Computational Linguistics. \n\nIf you need more information or details about this benchmark, feel free to ask!"
  },
  {
    "question": "Hi, I'm a researcher looking into advanced machine learning techniques. Could you tell me what approach was introduced in the study to improve retrieval-augmented generation?",
    "ground_truths": "An adaptive retrieval-augmented generation framework using a multi-armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity.",
    "reference": "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks.",
    "metadata": "situational",
    "retrieved_contexts": [
      "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks.",
      "1 Introduction and Related Work. Retrieval Augmented Generation (Lewis et al., 2020) has shown significant promise in addressing knowledge-intensive natural language processing (NLP) tasks by integrating an updated knowledge base with a language model. This combination allows language model to access up-to-date knowledge, improving their faithfulness and reducing hallucinations.Most existing RAG frameworks employ a retrieve-and-generate setup that indiscriminately performs retrieval based on the input.",
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs.",
      "Abstract. Retrieval Augmented Generation (RAG) has proven to be highly effective in boosting the generative performance of language model in knowledge-intensive tasks. However, existing RAG frameworks either indiscriminately perform retrieval or rely on rigid single-class classifiers to select retrieval methods, leading to inefficiencies and suboptimal performance across queries of varying complexity. To address these challenges, we propose a reinforcement learning-based framework that dynamically selects the most suitable retrieval strategy based on query complexity. Our approach leverages a multi-armed bandit algorithm, which treats each retrieval method as a distinct 'arm' and adapts the selection process by balancing exploration and exploitation. Additionally, we introduce a dynamic reward function that balances accuracy and efficiency, penalizing methods that require more retrieval steps, even if they lead to a correct result. Our method achieves new state-of-the-art results on multiple single-hop and multi-hop datasets while reducing retrieval costs. Our code is available at https://github.com/FUTUREEEEEE/MBA"
    ],
    "response": "The study introduced a novel approach called MBA-RAG, which stands for \"Multi-Armed Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity.\" This framework aims to enhance retrieval-augmented generation (RAG) by dynamically selecting the most appropriate retrieval strategy based on the complexity of the query.\n\nThe key features of this approach include:\n\n1. **Reinforcement Learning Framework**: It employs a reinforcement learning-based method to adaptively choose retrieval strategies.\n2. **Multi-Armed Bandit Algorithm**: Each retrieval method is treated as a distinct \"arm\" in a multi-armed bandit setup, allowing the system to balance exploration (trying out different methods) and exploitation (using the best-known method).\n3. **Dynamic Reward Function**: The framework includes a reward system that balances accuracy and efficiency, penalizing methods that require excessive retrieval steps, even if they yield correct results.\n\nThis approach has shown to achieve state-of-the-art results on various datasets while also reducing retrieval costs, addressing the inefficiencies of existing RAG frameworks that either perform indiscriminate retrieval or rely on rigid classifiers.\n\nThis information was derived from the context regarding the study's contributions to improving retrieval-augmented generation techniques."
  },
  {
    "question": "While planning my European trip and thinking about the diverse crowds in France, I came across a section on retrieval methods. Can you tell me what is introduced in that section?",
    "ground_truths": "A RAG framework based on a multi-arm bandit approach that dynamically selects the optimal generation method to balance generation quality and computational efficiency is introduced.",
    "reference": "2 Method. Using a single retrieval method for all queries may not always be effective. In this section, we introduce a RAG framework based on a multi-arm bandit approach that dynamically selects the optimal generation method to balance generation quality and computational efficiency.",
    "metadata": "situational",
    "retrieved_contexts": [
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs.",
      "However, this approach may hinder the versatility of language models or introduce unnecessary or off-topic* Equally contributed authors\u2020 Corresponding authorpassages. To address this issue, methods such as SEAKR (Yao et al., 2024) and FLARE (Jiang et al., 2023) have been designed to perform active retrieval only when necessary.Furthermore, AdaptiveRAG (Jeong et al., 2024) argues that real-world queries often vary in difficulty, such as the number of reasoning steps required or the depth of information needed to answer a query. Thus, applying a single retrieval method across all queries can be ineffective.",
      "Simple queries may incur unnecessary computational overhead when complex retrieval strategies are used, while complex, multi-step queries may not be adequately addressed. To tackle this issue, AdaptiveRAG introduces an adaptive router that selects the retrieval method based on the complexity of the query. However, AdaptiveRAG simplifies the retrieval strategy into a single-choice task by using heuristic supervision that favors only one process with the least retrieval cost. This supervision is inaccurate for two main reasons.",
      "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks."
    ],
    "response": "The section on retrieval methods discusses various strategies for enhancing retrieval efficiency in multi-step datasets. It highlights that the reward model does not only focus on the retrieval path with the fewest steps but also considers other viable paths. Notably, the method demonstrated over a 20% reduction in step costs, indicating a significant improvement in retrieval efficiency.\n\nAdditionally, it mentions that while the method performed comparably to Adaptive-RAG on the MusiQue dataset, it incurred lower step costs. However, on the HotpotQA dataset, it slightly underperformed in certain metrics compared to Adaptive-RAG, despite having lower step costs.\n\nThe section also addresses the potential limitations of using a single retrieval method for all queries, suggesting that different queries may require varying levels of complexity and reasoning. To tackle this, methods like SEAKR and FLARE have been introduced to perform active retrieval only when necessary.\n\nThis information was derived from the context provided, which discusses the performance and strategies of different retrieval methods."
  },
  {
    "question": "Hi there, I'm getting ready to attend a seminar about the philosophical aspects of a board game I patented, and I'm curious, what was Lizzie's creation that she sought to patent on 23 March 1903?",
    "ground_truths": "Lizzie sought to patent the Landlord's Game.",
    "reference": "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies. However, and of course unbeknownst to Lizzie at the time, it was the monopolist rules that would later capture the public's imagination.After years of tinkering, writing and pondering her new creation, Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
    "metadata": "situational",
    "retrieved_contexts": [
      "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies. However, and of course unbeknownst to Lizzie at the time, it was the monopolist rules that would later capture the public's imagination.After years of tinkering, writing and pondering her new creation, Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
      "She was angry, hurt and in search of revenge against a company that she felt had stolen her nowbest-selling idea. Parker Brothers might have the rights to her 1924-patented Landlord's Game, but they didn't tell the story of her game invention dating back to 1904 or that the game had been in the public domain for decades. She had invented the game, and she could prove it.The Evening Star reporter wrote that Lizzie's game 'did not get the popular hold it has today. It took Charles B Darrow, a Philadelphia engineer, who retrieved the game from the oblivion of the Patent Office and dressed it up a bit, to get it going.",
      "And so did Lizzie Magie. She died in 1948, a jobs was at the US Office of Education, where her colleagues knew her only as an elderly typist who talked about inventing games.As Charles Darrow reaped the rewards of the game's success, Lizzie Magie's role in the invention of Monopoly remained obscure. But in 1973, Ralph Anspach, a leftwing academic who was under legal attack from Parker Brothers over his creation of an Anti-Monopoly game, learned her story as he researched his case, seeking to undermine the company's hold on the intellectual property.",
      "Last August a large firm manufacturing games took over his improvements. In November, Mrs Phillips [Magie, who had by now married] sold the company her patent rights.'It went over with a bang. But not for Mrs Phillips \u2026 Probably, if one counts the lawyers', printers' and Patent Office fees used up in developing it, the game has cost her more than she made from it.' As she told the Washington Post in a story that ran the same day: 'There is nothing new under the sun.' widow with no children, whose obituary and headstone made no mention of her game invention. One of her lastIt was to little avail. Much to Lizzie's dismay, the other two games that she invented for Parker Brothers, King's Men and Bargain Day, received little publicity and faded into board-game obscurity. The newer, Parker Brothers version of the Landlord's Game appeared to have done so as well."
    ],
    "response": "Lizzie sought to patent her creation known as the \"Landlord's Game\" on March 23, 1903. This game was significant as it embodied her philosophical vision, which included elements of dualism and a tension between opposing philosophies. Despite her initial excitement about the game, she later felt wronged when she discovered that Parker Brothers had acquired the rights to her game without acknowledging her contributions. Ultimately, she received a one-time payment of $500 for the patent, but no royalties. \n\nThis information highlights the complexities surrounding her invention and the subsequent commercialization of her ideas."
  },
  {
    "question": "Hello, I'm a research assistant trying to understand how different reward settings impact information retrieval strategies. Could you explain what the reward settings are for the single-hop dataset in the MAB algorithm?",
    "ground_truths": "For the single-hop dataset, the rewards are set at 1, 0.9, and 1-step/10 respectively for the three retrieval strategies 'zero,' 'one,' and 'multiple'. When none of the three options can answer the question, the reward is set to -1.",
    "reference": "A.2 Reward Setting. For single-hop and multi-hop datasets, due to the differences in their tendencies for retrieval strategy selection, the single-hop dataset tends to choose the 'zero' and 'one' retrieval strategies, while the multi-hop dataset favors the 'one' and 'multiple' strategies. Therefore, for the MAB algorithm, the same set of rewards cannot achieve optimal results on both types of datasets simultaneously. Motivated by (Zhang et al., 2024), during our experiments, we set two different groups of reward settings.For the single-hop dataset, we adopted a dynamic reward approach, combining strategy selection with step costs to balance performance and efficiency, the rewards are set at 1, 0.9, and 1-step/10 respectively for the three retrieval strategies 'zero,' 'one,' and 'multiple,'. When none of the three options can answer the question, the reward is set to -1.For the multi-hop dataset, rewards are set at 4.3, 2.3, and 1.15.",
    "metadata": "situational",
    "retrieved_contexts": [
      "A.2 Reward Setting. For single-hop and multi-hop datasets, due to the differences in their tendencies for retrieval strategy selection, the single-hop dataset tends to choose the 'zero' and 'one' retrieval strategies, while the multi-hop dataset favors the 'one' and 'multiple' strategies. Therefore, for the MAB algorithm, the same set of rewards cannot achieve optimal results on both types of datasets simultaneously. Motivated by (Zhang et al., 2024), during our experiments, we set two different groups of reward settings.For the single-hop dataset, we adopted a dynamic reward approach, combining strategy selection with step costs to balance performance and efficiency, the rewards are set at 1, 0.9, and 1-step/10 respectively for the three retrieval strategies 'zero,' 'one,' and 'multiple,'. When none of the three options can answer the question, the reward is set to -1.For the multi-hop dataset, rewards are set at 4.3, 2.3, and 1.15.",
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs.",
      "The bandit framework requires only partial information for supervision; specifically, the model is supervised by the feedback of the chosen generation strategy, without indiscriminately penalizing the strategies that were not selected. This introduces greater flexibility by allowing the model to explore different generation strategies and obtain a more comprehensive selection.Second, to tackle the issue of inaccurate heuristic supervision of retrieval costs and the varying costs associated with different generation strategies, we design a dynamic, fine-grained reward function. This function penalizes inefficient generation strategies, even if they lead to correct results, ensuring that the model not only prioritizes accuracy but also optimizes computational efficiency.We evaluated our framework on both single-hop and multi-hop datasets. Results demonstrate that our method achieves SOTA generation accuracy while reducing retrieval costs by 20%.",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results."
    ],
    "response": "For the single-hop dataset in the MAB (Multi-Armed Bandit) algorithm, the reward settings are designed to balance performance and efficiency. Specifically, the rewards for the three retrieval strategies\u2014'zero,' 'one,' and 'multiple'\u2014are set as follows:\n\n- 'zero' strategy: Reward of 1\n- 'one' strategy: Reward of 0.9\n- 'multiple' strategy: Reward of 1-step/10\n\nAdditionally, if none of these strategies can answer the question, the reward is set to -1. \n\nThis dynamic reward approach is intended to encourage effective strategy selection while considering the associated step costs, thus optimizing both the accuracy of information retrieval and the computational efficiency. The context also notes that the single-hop dataset tends to favor the 'zero' and 'one' strategies, which informs the choice of these specific reward values.\n\nThis information was derived from the context that discusses the reward settings for the single-hop dataset in the MAB algorithm."
  },
  {
    "question": "Hello, I'm diving into some recent research on machine learning and came across a paper titled 'MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity.' Could you tell me which institutions the authors are affiliated with?",
    "ground_truths": "The institutions affiliated with the authors are The Hong Kong University of Science and Technology (Guangzhou), Tencent Hunyuan, Wuhan University, and Iowa State University.",
    "reference": "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn",
    "metadata": "situational",
    "retrieved_contexts": [
      "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results.",
      "1998. Reinforcement learning: An introduction. IEEE Transactions on Neural Networks , 9(5):1054-1054. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022a. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint arXiv:2212.10509 .Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022b. MuSiQue: Multihop questions via single-hop question composition. Transactions of the Association for Computational Linguistics , 10:539-554.Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning.",
      "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks."
    ],
    "response": "The authors of the paper titled \"MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity\" are affiliated with the following institutions:\n\n1. **The Hong Kong University of Science and Technology (Guangzhou)**\n2. **Tencent Hunyuan**\n3. **Wuhan University**\n4. **Iowa State University**\n\nThis information was derived from the author affiliations listed in the paper."
  },
  {
    "question": "Hi there, as a historian interested in the lesser-known stories of inventors, I'm curious about Lizzie Magie's contributions to board games. Specifically, what happened to the games she invented for Parker Brothers?",
    "ground_truths": "The other two games that she invented for Parker Brothers, King's Men and Bargain Day, received little publicity and faded into board-game obscurity.",
    "reference": "Last August a large firm manufacturing games took over his improvements. In November, Mrs Phillips [Magie, who had by now married] sold the company her patent rights.'It went over with a bang. But not for Mrs Phillips \u2026 Probably, if one counts the lawyers', printers' and Patent Office fees used up in developing it, the game has cost her more than she made from it.' As she told the Washington Post in a story that ran the same day: 'There is nothing new under the sun.' widow with no children, whose obituary and headstone made no mention of her game invention. One of her lastIt was to little avail. Much to Lizzie's dismay, the other two games that she invented for Parker Brothers, King's Men and Bargain Day, received little publicity and faded into board-game obscurity. The newer, Parker Brothers version of the Landlord's Game appeared to have done so as well.",
    "metadata": "situational",
    "retrieved_contexts": [
      "Last August a large firm manufacturing games took over his improvements. In November, Mrs Phillips [Magie, who had by now married] sold the company her patent rights.'It went over with a bang. But not for Mrs Phillips \u2026 Probably, if one counts the lawyers', printers' and Patent Office fees used up in developing it, the game has cost her more than she made from it.' As she told the Washington Post in a story that ran the same day: 'There is nothing new under the sun.' widow with no children, whose obituary and headstone made no mention of her game invention. One of her lastIt was to little avail. Much to Lizzie's dismay, the other two games that she invented for Parker Brothers, King's Men and Bargain Day, received little publicity and faded into board-game obscurity. The newer, Parker Brothers version of the Landlord's Game appeared to have done so as well.",
      "At least two years later, she published a version of the game through the Economic Game Company, a New York-based firm that counted Lizzie as a part-owner. The game became popular with leftwing intellectuals and on college campuses, and that popularity spread throughout the next three decades; it eventually caught on with a community of Quakers in Atlantic City, who customised it with the names of local neighbourhoods, and from there it found its way to Charles Darrow.In total, the game that Darrow brought to Parker Brothers has now sold hundreds of millions copies worldwide, and he received royalties throughout his life. ***Lizzy Magie's place in the game's folk history was lost for decades and ceded to the man who had picked it up at his friend's house - Charles Darrow. Photograph: AP***   `Summary of some image`   Lizzie was paid by Parker Brothers, too.",
      "And so did Lizzie Magie. She died in 1948, a jobs was at the US Office of Education, where her colleagues knew her only as an elderly typist who talked about inventing games.As Charles Darrow reaped the rewards of the game's success, Lizzie Magie's role in the invention of Monopoly remained obscure. But in 1973, Ralph Anspach, a leftwing academic who was under legal attack from Parker Brothers over his creation of an Anti-Monopoly game, learned her story as he researched his case, seeking to undermine the company's hold on the intellectual property.",
      "She was angry, hurt and in search of revenge against a company that she felt had stolen her nowbest-selling idea. Parker Brothers might have the rights to her 1924-patented Landlord's Game, but they didn't tell the story of her game invention dating back to 1904 or that the game had been in the public domain for decades. She had invented the game, and she could prove it.The Evening Star reporter wrote that Lizzie's game 'did not get the popular hold it has today. It took Charles B Darrow, a Philadelphia engineer, who retrieved the game from the oblivion of the Patent Office and dressed it up a bit, to get it going."
    ],
    "response": "Lizzie Magie's contributions to board games, particularly her invention of the Landlord's Game, have a complex history. After she published her version of the game through the Economic Game Company, it gained popularity among leftwing intellectuals and college campuses. This popularity eventually reached a community of Quakers in Atlantic City, who customized the game with local neighborhood names. From there, it caught the attention of Charles Darrow, who later brought a version of it to Parker Brothers.\n\nWhile the game became immensely successful under Darrow's name, selling hundreds of millions of copies worldwide, Lizzie Magie's contributions were largely overlooked for decades. She was compensated by Parker Brothers, but her other games, King's Men and Bargain Day, did not receive much attention and faded into obscurity. \n\nDespite her significant role in the development of what would become Monopoly, Magie's legacy remained largely unrecognized during her lifetime. She passed away in 1948, with her contributions to board games not acknowledged in her obituary or headstone. It wasn't until 1973 that her story began to resurface, thanks to Ralph Anspach, who was researching her contributions while facing legal challenges from Parker Brothers regarding his own game, Anti-Monopoly. \n\nIn summary, while Lizzie Magie played a crucial role in the creation of the Landlord's Game, her contributions were overshadowed by Charles Darrow's success, and her other games did not achieve the same recognition."
  },
  {
    "question": "Hello, as I'm researching adaptive retrieval strategies for computational data processing, could you explain what advantage MBA-RAG has over Adaptive-RAG in terms of strategy selection?",
    "ground_truths": "MBA-RAG achieved more optimal strategy selection with step costs lower than Adaptive-RAG, indicating balanced performance metrics with efficiency metrics.",
    "reference": "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results.",
    "metadata": "situational",
    "retrieved_contexts": [
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results.",
      "Simple queries may incur unnecessary computational overhead when complex retrieval strategies are used, while complex, multi-step queries may not be adequately addressed. To tackle this issue, AdaptiveRAG introduces an adaptive router that selects the retrieval method based on the complexity of the query. However, AdaptiveRAG simplifies the retrieval strategy into a single-choice task by using heuristic supervision that favors only one process with the least retrieval cost. This supervision is inaccurate for two main reasons.",
      "On the NQ dataset, our results are roughly on par with Adaptive-RAG, but with an increase in steps. This is because Adaptive-RAG, when constructing the dataset, set the condition that when zero, one, or multiple retrieval paths could yield the correct answer, the path requiring the fewest steps would be chosen as the correct label, with others marked as incorrect. However, this does not reflect reality as other paths can also yield correct answers.",
      "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks."
    ],
    "response": "MBA-RAG has a significant advantage over Adaptive-RAG in terms of strategy selection due to its more optimal approach to balancing performance and efficiency metrics. Specifically, MBA-RAG utilizes a bandit approach that allows for better strategy selection, resulting in lower step costs compared to Adaptive-RAG. This means that MBA-RAG can achieve effective retrieval without incurring excessive computational expenses.\n\nIn contrast, Adaptive-RAG simplifies the retrieval strategy into a single-choice task, which can lead to inefficiencies. It relies on heuristic supervision that favors the retrieval method with the least cost, which may not accurately reflect the complexities of different queries. As a result, while Adaptive-RAG may work well for straightforward queries, it can struggle with more complex, multi-step queries, potentially leading to suboptimal performance.\n\nAdditionally, MBA-RAG's multilabel supervising strategy is better suited to adapt to queries of varying complexities, which enhances its classification accuracy compared to Adaptive-RAG. This adaptability contributes to an overall improvement in retrieval results.\n\nIn summary, the advantages of MBA-RAG over Adaptive-RAG in strategy selection stem from its ability to balance performance with efficiency and its capacity to handle a wider range of query complexities effectively."
  },
  {
    "question": "How does Adaptive-RAG define the selection of retrieval strategies and why is this approach considered somewhat unreasonable?",
    "ground_truths": "Adaptive-RAG defines the selection of retrieval strategies as a single-label classification problem, selecting the strategy with the fewest steps as the correct label; however, this approach is considered somewhat unreasonable because it treats other correct choices as incorrect, even though they yield correct results with a higher step cost.",
    "reference": "A.3 Multi-label Classification. Due to Adaptive-RAG defining the selection of retrieval strategies as a single-label classification problem, where multiple strategies can yield correct results, it selects the strategy with the fewest   ***Table 3: Results of multi-label classification on each of a collection of datasets with FLAN-T5-XL (3B) as the LLM.***   `summary of some table`   steps as the correct label, treating other choices as incorrect. This approach is somewhat unreasonable because the other choices are also correct, albeit with a higher step cost.",
    "metadata": "double",
    "retrieved_contexts": [
      "Simple queries may incur unnecessary computational overhead when complex retrieval strategies are used, while complex, multi-step queries may not be adequately addressed. To tackle this issue, AdaptiveRAG introduces an adaptive router that selects the retrieval method based on the complexity of the query. However, AdaptiveRAG simplifies the retrieval strategy into a single-choice task by using heuristic supervision that favors only one process with the least retrieval cost. This supervision is inaccurate for two main reasons.",
      "On the NQ dataset, our results are roughly on par with Adaptive-RAG, but with an increase in steps. This is because Adaptive-RAG, when constructing the dataset, set the condition that when zero, one, or multiple retrieval paths could yield the correct answer, the path requiring the fewest steps would be chosen as the correct label, with others marked as incorrect. However, this does not reflect reality as other paths can also yield correct answers.",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results.",
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs."
    ],
    "response": "Adaptive-RAG defines the selection of retrieval strategies based on the complexity of the query, using an adaptive router that aims to optimize the retrieval process. The approach is designed to avoid unnecessary computational overhead by matching the retrieval strategy to the query's complexity\u2014simple queries should not use complex strategies, and vice versa.\n\nHowever, this approach is considered somewhat unreasonable because it simplifies the retrieval strategy into a single-choice task, relying on heuristic supervision that favors the method with the least retrieval cost. This can lead to inaccuracies since it does not account for the potential effectiveness of other retrieval paths that may not have the minimum steps but could still be viable options. \n\nThe context indicates that while Adaptive-RAG may achieve good performance metrics, it can sometimes lead to inefficiencies in retrieval costs, as demonstrated by the comparison with other methods that achieved similar performance with lower costs. Thus, the reliance on a single-choice heuristic may overlook more effective multi-step retrieval strategies that could better address complex queries."
  },
  {
    "question": "What happens if you are declared bankrupt and owe money to another player, and how are houses or hotels handled in a bankruptcy settlement?",
    "ground_truths": "If you are declared bankrupt and owe money to another player, you must turn over to that player all that you have of value and retire from the game; if you own houses or hotels, you must return these to the Bank in exchange for money to the extent of one-half the amount paid for them, and this cash is given to the creditor.",
    "reference": "You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your debt is to another player, you must tum over to that player all that you have of value and retire from the game. In making this settlement,  if you own houses or hotels, you must retum these to the Bank in exchange for money to the extent of one-half the amount paid for them;  this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay  .",
    "metadata": "double",
    "retrieved_contexts": [
      "You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your debt is to another player, you must tum over to that player all that you have of value and retire from the game. In making this settlement,  if you own houses or hotels, you must retum these to the Bank in exchange for money to the extent of one-half the amount paid for them;  this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay  .",
      "`Summary of some image`   The player who mortgages property  retains possession of it and no other player may secure it by lifting the mortgage from the Bank. However, the owner may sell this mortgaged property to another player at any agreed price. If you are the new owner, you may lift the mortgage at once if you wish by  paying off the mortgage plus 10% interest to the Bank. If the mortgage is not lifted at once, you must pay the Bank 10% interest  when you buy the property  and if you lift the mortgage later you must pay the Bank an additional 10% interest a s  well as   the amount of the mortgage. n-   `Summary of some image`   BANKRUPTCY..",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      ".(I) throwing doubles on any of your next three turns;  if you succeed in doing this you immediately  move forward the number of spaces shown by  your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3)  purchasing  the \"Get Out of Jail Free\" card from another player and playing it; (4)  paying a fine of $50 before  you roll the dice on either of your next two turns.If  you do not throw doubles by  your third turn, you must pay the $50 fine. Y o u  then get out of Jail and immediately move forward the number of spaces shown by  your throw.Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\" F R E E  P A R K I N G \" :  A player landing on this place does not receive any money, property or reward of any kind. This is just a \"free\" resting place.HOUSES: When you own all the propert~es in a color-group you may buy houses from the B a n k  and erect them on those properties.If  you buy one house, you may put it on any one of those properties."
    ],
    "response": "If you are declared bankrupt because you owe more than you can pay, either to another player or to the Bank, the following happens:\n\n1. **Debt to Another Player**: If your debt is to another player, you must turn over all your assets of value to that player and retire from the game. This means you give them everything you own.\n\n2. **Handling of Houses or Hotels**: If you own houses or hotels at the time of bankruptcy, you must return these to the Bank. In exchange, you receive cash equal to half the amount you originally paid for them. This cash is then given to your creditor (the player you owe money to).\n\n3. **Mortgaged Property**: If you have mortgaged properties, you also turn these over to your creditor. However, the new owner (the creditor) must pay off the mortgage immediately.\n\nThis process ensures that the player who is bankrupt settles their debts as fairly as possible before exiting the game."
  },
  {
    "question": "What is the backbone LLM used by Yao et al. (2024) for their results and what benefit does the approach mentioned provide in terms of retrieval strategies?",
    "ground_truths": "Yao et al. (2024) uses LLaMA-2-7B-Chat as the backbone LLM, and the approach achieves a substantial reduction in step costs, suggesting that it can dynamically select retrieval strategies with fewer retrieval steps.",
    "reference": "(2024), while items marked with \u2020 have results from Yao et al. (2024), which uses LLaMA-2-7B-Chat as the backbone LLM.***   `summary of some table`   SQuAD and TriviaQA datasets. In particular, our approach achieves a substantial reduction in step costs, suggesting that it can dynamically select retrieval strategies with fewer retrieval steps.",
    "metadata": "double",
    "retrieved_contexts": [
      "(2024), while items marked with \u2020 have results from Yao et al. (2024), which uses LLaMA-2-7B-Chat as the backbone LLM.***   `summary of some table`   SQuAD and TriviaQA datasets. In particular, our approach achieves a substantial reduction in step costs, suggesting that it can dynamically select retrieval strategies with fewer retrieval steps.",
      "Therefore, our reward model does not solely choose the retrieval path with the minimum steps but may also select other feasible paths.For the multi-step dataset, we have achieved a reduction in step costs of over 20%, clearly demonstrating a significant enhancement in the retrieval efficiency of our method. Our method achieved significant improvements on the 2wikiMultiHopQA. On the MusiQue dataset, we also achieved results comparable to Adaptive-RAG, but with significantly lower step costs. This indicates that when two retrieval strategies can achieve comparable performance metrics, our strategy incurs lower retrieval costs. However, on the HotpotQA dataset, our method slightly underperformed AdaptiveRAG in terms of EM, Accuracy, and F 1 , while having lower step costs.",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results.",
      "2.1 Preliminaries. The RAG process (Lewis et al., 2020) includes a retrieval stage where the module R retrieves relevant documents D for a query x , and a generation stage where the LLM uses x and D to generate the response \u00af a = LLM ( y t | x, D ) ."
    ],
    "response": "Yao et al. (2024) utilize LLaMA-2-7B-Chat as their backbone LLM for their research. The approach they mention provides significant benefits in terms of retrieval strategies by achieving a substantial reduction in step costs. This means that their method can dynamically select retrieval strategies that require fewer retrieval steps, enhancing retrieval efficiency.\n\nSpecifically, their method demonstrated over a 20% reduction in step costs on a multi-step dataset, indicating that it can effectively balance performance metrics with efficiency metrics. This is particularly advantageous when two retrieval strategies yield comparable performance, as their approach incurs lower retrieval costs. Overall, their strategy allows for optimal selection of retrieval paths while minimizing computational expenses, making it more efficient than other methods like Adaptive-RAG in certain contexts."
  },
  {
    "question": "What is HotpotQA and when was it introduced, and who are the authors of the paper titled 'Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation'?",
    "ground_truths": "HotpotQA is a dataset for diverse, explainable multi-hop question answering, introduced in 2018, and the authors of the paper 'Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation' are Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li.",
    "reference": "2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. 2024. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. Preprint , arXiv:2406.19215.Zhaofan Zhang, Yanan Xiao, Lu Jiang, Dingqi Yang, Minghao Yin, and Pengyang Wang. 2024. Spatialtemporal interplay in human mobility: A hierarchical reinforcement learning approach with hypergraph representation. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, pages 9396-9404.",
    "metadata": "double",
    "retrieved_contexts": [
      "2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. 2024. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. Preprint , arXiv:2406.19215.Zhaofan Zhang, Yanan Xiao, Lu Jiang, Dingqi Yang, Minghao Yin, and Pengyang Wang. 2024. Spatialtemporal interplay in human mobility: A hierarchical reinforcement learning approach with hypergraph representation. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, pages 9396-9404.",
      "2017. TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1601-1611, Vancouver, Canada. Association for Computational Linguistics.Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick SH Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In EMNLP (1) , pages 6769-6781.Michael N Katehakis and Arthur F Veinott Jr.",
      "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn",
      "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks."
    ],
    "response": "HotpotQA is a dataset designed for diverse and explainable multi-hop question answering, introduced in 2018. It was presented at the 2018 Conference on Empirical Methods in Natural Language Processing.\n\nThe authors of the paper titled \"Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation\" are Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. This paper is a preprint from 2024."
  },
  {
    "question": "What is the focus of the paper titled 'MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity' and which institutions are the authors affiliated with?",
    "ground_truths": "The paper focuses on a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity, and the authors are affiliated with The Hong Kong University of Science and Technology (Guangzhou), Tencent Hunyuan, Wuhan University, and Iowa State University.",
    "reference": "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn",
    "metadata": "double",
    "retrieved_contexts": [
      "MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity. Xiaqiang Tang * 1,2 , Qiang Gao *2,3 , Jian Li *2 , Nan Du 2 , Qi Li 4 , Sihong Xie \u2020 1 ,1 The Hong Kong University of Science and Technology (Guangzhou),2 Tencent Hunyuan, 3 Wuhan University, 4 Iowa State University,Correspondence:sihongxie@hkust-gz.edu.cn",
      "4 Conclusion. In this study, we introduced an adaptive retrievalaugmented generation framework using a multi-   ***Figure 2: On the left: classification accuracy of different adaptive approaches and the confusion matrix across all six datasets. On the right: we analyze MBA-RAG performance across different complexity labels, presenting the overall experimental results across six datasets.***   `Summary of some image`   armed bandit approach that dynamically selects the most efficient retrieval strategy based on query complexity. Our experimental results demonstrate the effectiveness of this method in reducing computational costs while maintaining high accuracy. Future work will aim to further refine this approach and explore its applicability to a broader range of NLP tasks.",
      "Abstract. Retrieval Augmented Generation (RAG) has proven to be highly effective in boosting the generative performance of language model in knowledge-intensive tasks. However, existing RAG frameworks either indiscriminately perform retrieval or rely on rigid single-class classifiers to select retrieval methods, leading to inefficiencies and suboptimal performance across queries of varying complexity. To address these challenges, we propose a reinforcement learning-based framework that dynamically selects the most suitable retrieval strategy based on query complexity. Our approach leverages a multi-armed bandit algorithm, which treats each retrieval method as a distinct 'arm' and adapts the selection process by balancing exploration and exploitation. Additionally, we introduce a dynamic reward function that balances accuracy and efficiency, penalizing methods that require more retrieval steps, even if they lead to a correct result. Our method achieves new state-of-the-art results on multiple single-hop and multi-hop datasets while reducing retrieval costs. Our code is available at https://github.com/FUTUREEEEEE/MBA",
      "DistilBERT's knowledge capabilities are not on par with T5. Nevertheless, our MBA-RAG still achieved more optimal strategy selection, with step costs lower than Adaptive-RAG, indicating that our MBA-RAG-based method has balanced performance metrics with efficiency metrics.Furthermore, as shown in Table 4, we compare our bandit approach with a multi-label classifier. Due to the classifier's inability to consider retrieval costs, it incurs excessive computational expenses, with the majority of queries opting for a multiple retrieval strategy. For more details, please refer to Appendix A.1.Retrieval Strategy Performance To measure the performance of different retrieval strategies, we compared the accuracy of label selection between our MBA-RAG-based classification strategy and other adaptive retrieval strategies. The results, as shown in Figure 2, indicate that our classification accuracy is significantly higher than that of Adaptive-RAG. This suggests that our multilabel supervising strategy is better suited to adapt to queries of varying complexities, leading to an overall improvement in results."
    ],
    "response": "The paper titled \"MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented Generation through Question Complexity\" focuses on developing an adaptive retrieval-augmented generation framework that utilizes a multi-armed bandit approach. This framework dynamically selects the most efficient retrieval strategy based on the complexity of the query. The study highlights the effectiveness of this method in reducing computational costs while maintaining high accuracy in knowledge-intensive tasks.\n\nThe authors of the paper are affiliated with the following institutions:\n1. The Hong Kong University of Science and Technology (Guangzhou)\n2. Tencent Hunyuan\n3. Wuhan University\n4. Iowa State University\n\nThis information was derived from the details provided about the paper and its authors."
  },
  {
    "question": "What was the nature of Lizzie's vision for her creation and when did she enter the US Patent Office to secure her legal claim to the Landlord's Game?",
    "ground_truths": "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies, and Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
    "reference": "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies. However, and of course unbeknownst to Lizzie at the time, it was the monopolist rules that would later capture the public's imagination.After years of tinkering, writing and pondering her new creation, Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
    "metadata": "double",
    "retrieved_contexts": [
      "Her vision was an embrace of dualism and contained a contradiction within itself, a tension trying to be resolved between opposing philosophies. However, and of course unbeknownst to Lizzie at the time, it was the monopolist rules that would later capture the public's imagination.After years of tinkering, writing and pondering her new creation, Lizzie entered the US Patent Office on 23 March 1903 to secure her legal claim to the Landlord's Game.",
      "When the game started to take off in the mid-1930s, the company bought up the rights to other related games to preserve its territory. For the patent to the Landlord's Game and two other game ideas, Lizzie reportedly received $500 - and no royalties.At first, Lizzie did not suspect the true motives for the purchase of her game. When a prototype of Parker Brothers' version of the Landlord's Game arrived at her home in Arlington, she was delighted. In a letter to Foster Parker, nephew of George and the company's treasurer, she wrote that there had been 'a song in my heart' ever since the game had arrived. 'Some day, I hope,' she went on, 'you will publish other games of mine, but I don't think any one of them will be as much trouble to you or as important to me as this one, and I'm sure I wouldn't make so much fuss over them.'Eventually, though, the truth dawned on her - and she became publicly angry. In January of 1936 she gave interviews to the Washington Post and the Washington Evening Star.",
      "She was angry, hurt and in search of revenge against a company that she felt had stolen her nowbest-selling idea. Parker Brothers might have the rights to her 1924-patented Landlord's Game, but they didn't tell the story of her game invention dating back to 1904 or that the game had been in the public domain for decades. She had invented the game, and she could prove it.The Evening Star reporter wrote that Lizzie's game 'did not get the popular hold it has today. It took Charles B Darrow, a Philadelphia engineer, who retrieved the game from the oblivion of the Patent Office and dressed it up a bit, to get it going.",
      "Serving out their time meant waiting until they threw a double. 'The rallying and chaffing of the others when one player finds himself an inmate of the jail, and the expressions of mock sympathy and condolence when one is obliged to betake himself to the poor house, make a large part of the fun and merriment of the game,' Lizzie said.From its inception, the Landlord's Game aimed to seize on the natural human instinct to compete. And, somewhat surprisingly, Lizzie created two sets of rules: an anti-monopolist set in which all were rewarded when wealth was created, and a monopolist set in which the goal was to create monopolies and crush opponents."
    ],
    "response": "Lizzie's vision for her creation, the Landlord's Game, was characterized by an embrace of dualism, reflecting a tension between opposing philosophies. This complexity in her vision was somewhat contradictory, as it later became the monopolist rules that captured the public's imagination.\n\nShe entered the US Patent Office on March 23, 1903, to secure her legal claim to the Landlord's Game. Despite her initial excitement about the game's success and the interest from Parker Brothers, she later felt betrayed when she realized the company had not acknowledged her original invention and had effectively taken control of her creation. \n\nThis information was derived from the context regarding Lizzie's vision and her patenting of the game."
  },
  {
    "question": "What happens when a player mortgages a property in the game, and can a mortgaged property be sold to another player, and what are the conditions if it is?",
    "ground_truths": "When a player mortgages a property, they retain possession and no other player may lift the mortgage from the Bank. However, the owner may sell this mortgaged property to another player at any agreed price. The new owner can lift the mortgage immediately by paying off the mortgage plus 10% interest to the Bank. If not lifted immediately, the new owner must pay 10% interest when buying the property, and if the mortgage is lifted later, an additional 10% interest plus the mortgage amount must be paid.",
    "reference": "`Summary of some image`   The player who mortgages property  retains possession of it and no other player may secure it by lifting the mortgage from the Bank. However, the owner may sell this mortgaged property to another player at any agreed price. If you are the new owner, you may lift the mortgage at once if you wish by  paying off the mortgage plus 10% interest to the Bank. If the mortgage is not lifted at once, you must pay the Bank 10% interest  when you buy the property  and if you lift the mortgage later you must pay the Bank an additional 10% interest a s  well as   the amount of the mortgage. n-   `Summary of some image`   BANKRUPTCY..",
    "metadata": "double",
    "retrieved_contexts": [
      "`Summary of some image`   The player who mortgages property  retains possession of it and no other player may secure it by lifting the mortgage from the Bank. However, the owner may sell this mortgaged property to another player at any agreed price. If you are the new owner, you may lift the mortgage at once if you wish by  paying off the mortgage plus 10% interest to the Bank. If the mortgage is not lifted at once, you must pay the Bank 10% interest  when you buy the property  and if you lift the mortgage later you must pay the Bank an additional 10% interest a s  well as   the amount of the mortgage. n-   `Summary of some image`   BANKRUPTCY..",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      "You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your debt is to another player, you must tum over to that player all that you have of value and retire from the game. In making this settlement,  if you own houses or hotels, you must retum these to the Bank in exchange for money to the extent of one-half the amount paid for them;  this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay  .",
      "the Bank the amount of interest  on the loan, which is 10% of the value of the property. The new owner who does this may then, at hislher option, pay the principal  or hold  the property  until some later turn,  then lift the mortgage. If helshe holds property in this way until a later turn,  helshe must pay the interest again upon lifting the mortgage.Should you owe the Bank,  instead of another player, more than you can pay (because of taxes or penalties) even by  selling off buildings and mortgaging property,  you must turn over all assets to the Bank. In this case, the Bank immediately sells by  auction all property so taken, except buildings. A bankrupt player must immediately retire from the game. The last player left in the game wins.MISCEUANEOUS: Money can be loaned to a player only by the Bank and then only by mortgaging property. No player may borrow from or lend money to another player."
    ],
    "response": "When a player mortgages a property in the game, they retain possession of it, meaning they still own the property but cannot collect rent on it. Other players cannot lift the mortgage from the Bank. However, the player who mortgaged the property can sell it to another player at any agreed price.\n\nIf a mortgaged property is sold to another player, the new owner has the option to lift the mortgage immediately by paying off the mortgage amount plus an additional 10% interest to the Bank. If the new owner chooses not to lift the mortgage right away, they must pay the Bank 10% interest at the time of purchase. Later, if they decide to lift the mortgage, they will need to pay the original mortgage amount plus another 10% interest.\n\nThis information was derived from the context regarding the rules of mortgaging properties and the conditions surrounding the sale of mortgaged properties."
  },
  {
    "question": "What limitation does the strategy assumption impose on query answering and what are some strategies mentioned for answering queries?",
    "ground_truths": "The strategy assumption imposes the limitation that it assumes only one strategy is optimal for one query, marking only the direct answer method as correct, even though multiple strategies might provide correct answers. The strategies mentioned for answering queries include directly answering without retrieval, retrieving once, or performing iterative retrieval.",
    "reference": "First, it assumes only one strategy is optimal for one query. For example, while multiple strategies (such as directly answering without retrieval, retrieving once, or performing iterative retrieval) might all provide correct answers depending on the query, only the direct answer method will be marked as correct.",
    "metadata": "double",
    "retrieved_contexts": [
      "First, it assumes only one strategy is optimal for one query. For example, while multiple strategies (such as directly answering without retrieval, retrieving once, or performing iterative retrieval) might all provide correct answers depending on the query, only the direct answer method will be marked as correct.",
      "Simple queries may incur unnecessary computational overhead when complex retrieval strategies are used, while complex, multi-step queries may not be adequately addressed. To tackle this issue, AdaptiveRAG introduces an adaptive router that selects the retrieval method based on the complexity of the query. However, AdaptiveRAG simplifies the retrieval strategy into a single-choice task by using heuristic supervision that favors only one process with the least retrieval cost. This supervision is inaccurate for two main reasons.",
      "This strict supervision ignores scenarios where more complex strategies might offer better context or more comprehensive answers. Second, this heuristic approach is ambiguous because retrieval costs vary according to the query's difficulty, what constitutes the least cost can differ significantly between queries of different complexities.To overcome these limitations, we propose a M ulti-arm B andit-based framework for A daptive R etrievalA ugmented G eneration (MBA-RAG) Fig. 1, that introduces both flexibility and costawareness into the generation process.First, to address the rigidity of single-label supervision, we employ a multi-armed bandit algo-   ***Figure 1: On the left, the AdaptiveRAG pipeline relies on an inaccurate heuristic approach to assign queries of different complexities to a single generation process. On the right, we propose an MBA-RAG framework that allows the model to explore the merits of different generation methods and rewards it based on fine-grained assessments of generation quality and cost.***   `Summary of some image`   rithm (Katehakis and Veinott Jr, 1987).",
      "However, this approach may hinder the versatility of language models or introduce unnecessary or off-topic* Equally contributed authors\u2020 Corresponding authorpassages. To address this issue, methods such as SEAKR (Yao et al., 2024) and FLARE (Jiang et al., 2023) have been designed to perform active retrieval only when necessary.Furthermore, AdaptiveRAG (Jeong et al., 2024) argues that real-world queries often vary in difficulty, such as the number of reasoning steps required or the depth of information needed to answer a query. Thus, applying a single retrieval method across all queries can be ineffective."
    ],
    "response": "The strategy assumption imposes a limitation on query answering by suggesting that only one strategy is optimal for a given query. This means that even though multiple strategies (like directly answering without retrieval, retrieving once, or performing iterative retrieval) could yield correct answers, only the direct answer method is recognized as correct. This can lead to inefficiencies, as simple queries might incur unnecessary computational costs when more complex retrieval strategies are employed, and complex queries may not be adequately addressed.\n\nTo address these limitations, several strategies are mentioned:\n\n1. **Adaptive Router**: This strategy selects the retrieval method based on the complexity of the query, allowing for a more tailored approach to answering.\n\n2. **Multi-armed Bandit-based Framework (MBA-RAG)**: This framework introduces flexibility and cost-awareness into the generation process, allowing the model to explore different generation methods and assess them based on quality and cost.\n\nThese strategies aim to overcome the rigidity of single-label supervision and improve the overall effectiveness of query answering by adapting to the specific needs of each query."
  },
  {
    "question": "What are they?",
    "ground_truths": "The options for getting out of jail are: (1) throwing doubles on any of your next three turns, (2) using the 'Get Out of Jail Free' card if you have it, (3) purchasing the 'Get Out of Jail Free' card from another player and playing it, and (4) paying a fine of $50 before you roll the dice on either of your next two turns.",
    "reference": ".(I) throwing doubles on any of your next three turns;  if you succeed in doing this you immediately  move forward the number of spaces shown by  your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3)  purchasing  the \"Get Out of Jail Free\" card from another player and playing it; (4)  paying a fine of $50 before  you roll the dice on either of your next two turns.If  you do not throw doubles by  your third turn, you must pay the $50 fine. Y o u  then get out of Jail and immediately move forward the number of spaces shown by  your throw.Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\" F R E E  P A R K I N G \" :  A player landing on this place does not receive any money, property or reward of any kind. This is just a \"free\" resting place.HOUSES: When you own all the propert~es in a color-group you may buy houses from the B a n k  and erect them on those properties.If  you buy one house, you may put it on any one of those properties.",
    "metadata": "conversational",
    "retrieved_contexts": [
      "Therefore, to make the classification choice more rational while considering step costs, we implemented a multi-label classification setup, treating all retrieval strategies that could yield the correct answer as correct labels. We trained the classification model to predict multiple potential labels and selected the most likely label during the final inference.",
      "If there are a limited number of houses and hotels available and two or more players wish to buy more than the B a n k  h a s ,   the houses or hotels must be  sold at auction to the highest bidder.SELLING PROPERN: Unimproved  properties, railroads and util~ties (but not buildings) may be sold to any player a s  a private transaction for any amount the owner can get;  however, no property can be sold to another player if buildings are standing on any properties of that colorgroup.",
      "CLASSIC MONOPOW RULES. OBJECT: The object of the game IS to become the wealthiest player through buying, renting and selling property.PREPARATION: Place the board on a table and put the Chance and Community Chest cards facedown on their allotted spaces on the board. Each player chooses one token to represent himther while traveling around the board.Each player is given $1,500 divided as follows: P each of $500s, $ 1 0 0 ~ and $50~; 6 $40~; 5 each of $105, $ 5 ~ and $Is.All remaining money and other equipment go to the Bank. Stack the Bank's money on edge in the compartments in the plastic Banker's tray.BANKER.",
      "It sells and auctions properties and hands out the~r proper  Title Deed cards; it sells houses and hotels to the players and loans money when required on mortgages. `Summary of some image`   The Bank collects all taxes, fines,  loans and interest, and the price of all properties  which it sells and  auctions.The Bank nwer \"goes broke.\" If the Bank runs out of money, the Banker may issue a s   much more a s   needed by  writing on any ordinary paper.THE PLAY: Starting with the Banker, each player in turn throws the dice. `Summary of some image`   The player with the highest total starts the play: Place your token on the corner marked \"GO,\" throw the dice and move your token in the direction of the arrow the number of spaces indicated by  the dice."
    ],
    "response": "The context provided discusses a multi-label classification setup and mentions rules related to a property trading game, likely Monopoly. However, it does not specify what \"they\" refers to in your question. \n\nIf you could clarify what you mean by \"they,\" I would be happy to assist you further. As it stands, the information needed to answer your question was not found in the database."
  },
  {
    "question": "What are the options for them?",
    "ground_truths": "If you land on 'INCOME TAX', you have two options: You may estimate your tax at $900 and pay the Bank, or you may pay 10% of your total worth to the Bank.",
    "reference": "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
    "metadata": "conversational",
    "retrieved_contexts": [
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      "After you have completed your play, the turn passes to the left. The tokens remain on the spaces qccupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time.According to the space your token reaches, you may be entitled  to buy real estate or other properties  or obliged  to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc.If you throw doubles, you move your token a s   usual, the sum of the two dice, and are subject to any privileges  or penalties pertaining  to the space on which you land. Retaining the dice, throw again and move your token a s   before.",
      "First, it assumes only one strategy is optimal for one query. For example, while multiple strategies (such as directly answering without retrieval, retrieving once, or performing iterative retrieval) might all provide correct answers depending on the query, only the direct answer method will be marked as correct.",
      "If there are a limited number of houses and hotels available and two or more players wish to buy more than the B a n k  h a s ,   the houses or hotels must be  sold at auction to the highest bidder.SELLING PROPERN: Unimproved  properties, railroads and util~ties (but not buildings) may be sold to any player a s  a private transaction for any amount the owner can get;  however, no property can be sold to another player if buildings are standing on any properties of that colorgroup."
    ],
    "response": "The options available depend on the context of the game being played. For example, if a player lands on \"INCOME TAX,\" they have two choices: \n\n1. Estimate their tax at $900 and pay that amount to the Bank.\n2. Pay 10% of their total worth to the Bank, which includes all cash on hand, the printed prices of mortgaged and unmortgaged properties, and the cost price of all buildings they own.\n\nAdditionally, if a player draws a card that they do not wish to use, they can sell it to another player at a mutually agreeable price.\n\nThese options illustrate the decisions players must make based on their circumstances in the game."
  },
  {
    "question": "Who are they?",
    "ground_truths": "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal.",
    "reference": "1998. Reinforcement learning: An introduction. IEEE Transactions on Neural Networks , 9(5):1054-1054. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022a. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint arXiv:2212.10509 .Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022b. MuSiQue: Multihop questions via single-hop question composition. Transactions of the Association for Computational Linguistics , 10:539-554.Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning.",
    "metadata": "conversational",
    "retrieved_contexts": [
      "Select a s   Banker a player who will also make a good Auctioneer A Banker who plays ~n  the game must keep hislher personal funds separate from those of the Bank. When more than f~ve persons play, the Banker may elect to act only as   Banker and Auctioneer.THE BANK: Besides the Bank's money, the Bank holds the Title Deed cards and houses and hotels prior to purchase and use by the players. The Bank pays salaries and bonuses.",
      "LWe will be happy to hear your questions or comments about this game. Write to: Hasbro Games,  Consumer Affairs Dept., P.O. Box 200, Pawtucket, R I   02862. Tel: 888-836-7025 (toll free). Canadian consumers please  write to: Hasbro Canada Corporation, 2350 de la Province, Longueuil, QC Canada, J4 G 1G2.The HASBRO, PARKER BROTHERS, and MONOPOLY names and logos, the distinctive design of the gameboard, the fo u r   comer squares, the MR. MONOPOLY name and character, and each o f   the distinctive elements of the board and rules are trademarks o f Hasbro for its property trading game and game equipment. 02004,2007 Hasbro, Pawtucket, RI 02862. All Rights Reserved. TM & @ 3 denote U.S. Trademarks.00009-1   ``   `Summary of some image`   `Summary of some image`   ,",
      "Most people know about the Wright brothers - who filed their patent on the same day as Lizzie Magie - but don't recall the other aviators who also sought to fly. The adage that success has many fathers, but we remember only one, rings true - to say nothing of success's mothers. Everyone who has ever played Monopoly, even today, has added to its remarkable endurance and, on some level, made it their own.",
      "Therefore, to make the classification choice more rational while considering step costs, we implemented a multi-label classification setup, treating all retrieval strategies that could yield the correct answer as correct labels. We trained the classification model to predict multiple potential labels and selected the most likely label during the final inference."
    ],
    "response": "The context does not provide specific information about \"who they are.\" However, it mentions the Wright brothers and Lizzie Magie in relation to aviation and the game Monopoly, suggesting that \"they\" could refer to notable figures in these contexts. Unfortunately, without more details, I cannot provide a definitive answer about who \"they\" are. If you have a specific group or context in mind, please provide more information."
  },
  {
    "question": "What does it use for that?",
    "ground_truths": "The RAG framework uses a multi-arm bandit approach to dynamically select the optimal generation method.",
    "reference": "2 Method. Using a single retrieval method for all queries may not always be effective. In this section, we introduce a RAG framework based on a multi-arm bandit approach that dynamically selects the optimal generation method to balance generation quality and computational efficiency.",
    "metadata": "conversational",
    "retrieved_contexts": [
      "It sells and auctions properties and hands out the~r proper  Title Deed cards; it sells houses and hotels to the players and loans money when required on mortgages. `Summary of some image`   The Bank collects all taxes, fines,  loans and interest, and the price of all properties  which it sells and  auctions.The Bank nwer \"goes broke.\" If the Bank runs out of money, the Banker may issue a s   much more a s   needed by  writing on any ordinary paper.THE PLAY: Starting with the Banker, each player in turn throws the dice. `Summary of some image`   The player with the highest total starts the play: Place your token on the corner marked \"GO,\" throw the dice and move your token in the direction of the arrow the number of spaces indicated by  the dice.",
      "After you have completed your play, the turn passes to the left. The tokens remain on the spaces qccupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time.According to the space your token reaches, you may be entitled  to buy real estate or other properties  or obliged  to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc.If you throw doubles, you move your token a s   usual, the sum of the two dice, and are subject to any privileges  or penalties pertaining  to the space on which you land. Retaining the dice, throw again and move your token a s   before.",
      ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when."
    ],
    "response": "The context indicates that it uses various mechanisms to manage properties and finances in a game setting. Specifically, it sells and auctions properties, issues Title Deed cards, sells houses and hotels to players, and provides loans when necessary. The Bank is responsible for collecting taxes, fines, loans, and interest, as well as the prices of properties sold and auctioned. If the Bank runs out of money, it can issue more by writing on ordinary paper.\n\nThis information helps clarify how the system operates in terms of property management and financial transactions within the game."
  },
  {
    "question": "What happens then?",
    "ground_truths": "If you throw doubles three times in succession, move your token immediately to the space marked 'In Jail'.",
    "reference": "If  you throw doubles three times in succession, move your token immediately to the space marked \"In Jail\" (see JAIL).. .\"GO\": Each time a player's token lands on or passes over GO, whether by throwing the dice or drawing a card, the Banker pays himther a $200  sala,ry.The $200 is paid only once each time kound the board. However, if a player passing GO on the throw of the dice lands 2 spaces beyond it on Community Chest, or 7 spaces beyond it on Chance, and draws the \"Advance to GO\" card, helshe  collects $200 for passing GO the first time and another $200 for reaching it the second time by instructions on the card. `Summary of some image`   BUYING PROPERTY: Whenever you land on an unowned property you may buy that property from the Bank at its printed price.",
    "metadata": "conversational",
    "retrieved_contexts": [
      "After you have completed your play, the turn passes to the left. The tokens remain on the spaces qccupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time.According to the space your token reaches, you may be entitled  to buy real estate or other properties  or obliged  to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc.If you throw doubles, you move your token a s   usual, the sum of the two dice, and are subject to any privileges  or penalties pertaining  to the space on which you land. Retaining the dice, throw again and move your token a s   before.",
      ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      "You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your debt is to another player, you must tum over to that player all that you have of value and retire from the game. In making this settlement,  if you own houses or hotels, you must retum these to the Bank in exchange for money to the extent of one-half the amount paid for them;  this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay  ."
    ],
    "response": "When you complete your play, the turn passes to the next player on the left. The tokens remain on the spaces they occupy and will continue from that point on the player's next turn. Depending on the space your token lands on, you may have various actions to take, such as buying real estate, paying rent or taxes, or drawing a Chance or Community Chest card. \n\nIf you roll doubles, you move your token according to the sum of the two dice and can throw again. However, if your token lands on \"Go to Jail,\" you draw a card that sends you to Jail, or you roll doubles three times in a row, you must move directly to Jail, ending your turn. While in Jail, you cannot collect your salary. If you land on the Jail space without being sent there, you are \"Just Visiting\" and can continue your turn normally.\n\nAdditionally, if you land on the \"Income Tax\" space, you have two options: pay a flat fee of $900 or pay 10% of your total worth, which includes cash and the value of your properties. You must decide which option to take before calculating your total worth. \n\nThis information outlines the rules and consequences of gameplay actions based on the context provided."
  },
  {
    "question": "What is suggested?",
    "ground_truths": "A Multi-arm Bandit-based framework for Adaptive Retrieval-Augmented Generation (MBA-RAG) is proposed to introduce flexibility and cost-awareness into the generation process.",
    "reference": "This strict supervision ignores scenarios where more complex strategies might offer better context or more comprehensive answers. Second, this heuristic approach is ambiguous because retrieval costs vary according to the query's difficulty, what constitutes the least cost can differ significantly between queries of different complexities.To overcome these limitations, we propose a M ulti-arm B andit-based framework for A daptive R etrievalA ugmented G eneration (MBA-RAG) Fig. 1, that introduces both flexibility and costawareness into the generation process.First, to address the rigidity of single-label supervision, we employ a multi-armed bandit algo-   ***Figure 1: On the left, the AdaptiveRAG pipeline relies on an inaccurate heuristic approach to assign queries of different complexities to a single generation process. On the right, we propose an MBA-RAG framework that allows the model to explore the merits of different generation methods and rewards it based on fine-grained assessments of generation quality and cost.***   `Summary of some image`   rithm (Katehakis and Veinott Jr, 1987).",
    "metadata": "conversational",
    "retrieved_contexts": [
      "First, it assumes only one strategy is optimal for one query. For example, while multiple strategies (such as directly answering without retrieval, retrieving once, or performing iterative retrieval) might all provide correct answers depending on the query, only the direct answer method will be marked as correct.",
      "Therefore, to make the classification choice more rational while considering step costs, we implemented a multi-label classification setup, treating all retrieval strategies that could yield the correct answer as correct labels. We trained the classification model to predict multiple potential labels and selected the most likely label during the final inference.",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      "T h e  next house you buy must be erected on one of the unimproved properties of this or any other complete  colorgroup you may own.The price you must pay the B a n k  for each house is shown on your ltle  Deed card for the property  on which you erect the house. `Summary of some image`   The owner still collects double rent from an opponent who lands on the unimproved properties of hisher complete  color-group.Following the above rules, you may buy and erect at any time a s many houses a s  your judgement and financial standing  will allow. But you must build evenly, i.e., you cannot erect more than one house on any one property  of any color-group until you have built one house on wery property of that group."
    ],
    "response": "The context suggests a multi-label classification approach for determining optimal strategies in response to queries. It highlights that while multiple strategies may yield correct answers, only one method is typically marked as correct. To improve rationality in classification, the implementation allows for multiple potential labels to be considered correct, thus enabling the model to predict and select the most likely label during inference.\n\nThis approach is beneficial in scenarios where various methods can lead to accurate outcomes, ensuring a more comprehensive evaluation of possible strategies. \n\nIf you have a specific area or topic in mind regarding what is suggested, please provide more details for a more tailored response."
  },
  {
    "question": "What are they?",
    "ground_truths": "For single-hop datasets, the Wikipedia corpus preprocessed by Karpukhin et al., 2020 is used, and for multihop datasets, the preprocessed corpus by Trivedi et al., 2022a is used.",
    "reference": "A.1 Implementation Details. For the external document corpus, we use different sources depending on the dataset type: the Wikipedia corpus preprocessed by(Karpukhin et al., 2020) for single-hop datasets, and the preprocessed corpus by (Trivedi et al., 2022a) for multihop datasets. Approaches such as those proposed by (Sun et al., 2024b,a) can be utilized to accelerate the training process.",
    "metadata": "conversational",
    "retrieved_contexts": [
      "Therefore, to make the classification choice more rational while considering step costs, we implemented a multi-label classification setup, treating all retrieval strategies that could yield the correct answer as correct labels. We trained the classification model to predict multiple potential labels and selected the most likely label during the final inference.",
      "If there are a limited number of houses and hotels available and two or more players wish to buy more than the B a n k  h a s ,   the houses or hotels must be  sold at auction to the highest bidder.SELLING PROPERN: Unimproved  properties, railroads and util~ties (but not buildings) may be sold to any player a s  a private transaction for any amount the owner can get;  however, no property can be sold to another player if buildings are standing on any properties of that colorgroup.",
      "CLASSIC MONOPOW RULES. OBJECT: The object of the game IS to become the wealthiest player through buying, renting and selling property.PREPARATION: Place the board on a table and put the Chance and Community Chest cards facedown on their allotted spaces on the board. Each player chooses one token to represent himther while traveling around the board.Each player is given $1,500 divided as follows: P each of $500s, $ 1 0 0 ~ and $50~; 6 $40~; 5 each of $105, $ 5 ~ and $Is.All remaining money and other equipment go to the Bank. Stack the Bank's money on edge in the compartments in the plastic Banker's tray.BANKER.",
      "It sells and auctions properties and hands out the~r proper  Title Deed cards; it sells houses and hotels to the players and loans money when required on mortgages. `Summary of some image`   The Bank collects all taxes, fines,  loans and interest, and the price of all properties  which it sells and  auctions.The Bank nwer \"goes broke.\" If the Bank runs out of money, the Banker may issue a s   much more a s   needed by  writing on any ordinary paper.THE PLAY: Starting with the Banker, each player in turn throws the dice. `Summary of some image`   The player with the highest total starts the play: Place your token on the corner marked \"GO,\" throw the dice and move your token in the direction of the arrow the number of spaces indicated by  the dice."
    ],
    "response": "The context provided discusses a multi-label classification setup and mentions rules related to a board game, specifically Monopoly. However, it does not specify what \"they\" refers to in your question. \n\nBased on the information available, I cannot determine what \"they\" are. If you have a specific subject in mind or need clarification on a particular topic, please provide more details."
  },
  {
    "question": "What happens then?",
    "ground_truths": "If the Bank runs out of money, the Banker may issue as much more as needed by writing on any ordinary paper.",
    "reference": "It sells and auctions properties and hands out the~r proper  Title Deed cards; it sells houses and hotels to the players and loans money when required on mortgages. `Summary of some image`   The Bank collects all taxes, fines,  loans and interest, and the price of all properties  which it sells and  auctions.The Bank nwer \"goes broke.\" If the Bank runs out of money, the Banker may issue a s   much more a s   needed by  writing on any ordinary paper.THE PLAY: Starting with the Banker, each player in turn throws the dice. `Summary of some image`   The player with the highest total starts the play: Place your token on the corner marked \"GO,\" throw the dice and move your token in the direction of the arrow the number of spaces indicated by  the dice.",
    "metadata": "conversational",
    "retrieved_contexts": [
      "After you have completed your play, the turn passes to the left. The tokens remain on the spaces qccupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time.According to the space your token reaches, you may be entitled  to buy real estate or other properties  or obliged  to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc.If you throw doubles, you move your token a s   usual, the sum of the two dice, and are subject to any privileges  or penalties pertaining  to the space on which you land. Retaining the dice, throw again and move your token a s   before.",
      ". . ( I ) your token lands on the space marked \"Go to Jail\"; (2) you draw a card marked \"Go to JailN;  or (3) you throw doubles three times in succession. `Summary of some image`   When you are sent to Jail you cannot collect your $200 salary in that move since,  regardless of where your token i s  o n  the board, you must move it directly into Jail. Your turn ends when you are sent to Jail.If  you are not \"sent\" to Jail but in the ordinary course of play land  on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.You get out of Jail by..",
      "If the player who draws it does not wish to use it, helshe may sell it, at a n y  time, to another player a t  a price agreeable to both.\"I N C O ME TAX\": If  you land here you have two options: Y o u  may estimate  your tax at $900 and pay the B a n k ,   or you m a y  pay 10% of your total worth to the Bank. Y o u r   total worth i s  all your c a s h  on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own.You must decide which option you will take before you add up your total worth.\"JAIL\":  You land in Jail when.",
      "You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your debt is to another player, you must tum over to that player all that you have of value and retire from the game. In making this settlement,  if you own houses or hotels, you must retum these to the Bank in exchange for money to the extent of one-half the amount paid for them;  this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay  ."
    ],
    "response": "When you complete your turn in the game, the turn passes to the player on your left. The tokens remain on the spaces they occupy, and the next player will continue from that point on their turn. Depending on the space your token lands on, you may have various actions to take, such as buying real estate, paying rent or taxes, or drawing a Chance or Community Chest card.\n\nIf you roll doubles, you move your token the total of the two dice and may take additional actions based on the space you land on. However, if your token lands on \"Go to Jail,\" you must move directly to Jail, and your turn ends. While in Jail, you cannot collect your salary for that turn. If you land on Jail without being sent there, you are \"Just Visiting\" and can continue your turn as normal.\n\nYou also have options when landing on \"Income Tax,\" where you can either pay a flat fee or a percentage of your total worth. You must decide which option to take before calculating your total worth.\n\nThis information was derived from the context regarding game rules and player actions."
  }
]